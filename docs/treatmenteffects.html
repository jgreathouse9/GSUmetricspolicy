<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Econometrics for Policy Analysis - 7&nbsp; Causal Inference</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./ols.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Causal Inference</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Econometrics for Policy Analysis</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Syllabus: PMAP 4041, Fall 2024</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./module1.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Data and Policy Studies</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Mathematics and Econometric Theory</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./basicprob.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Basic Probability Theory</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./asymptotic.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Asymptotic Theory</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./correlation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Correlation and Association</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ols.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">OLS Explained</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./treatmenteffects.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Causal Inference</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">Applied Research Methods</span>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#what-is-causality" id="toc-what-is-causality" class="nav-link active" data-scroll-target="#what-is-causality"><span class="toc-section-number">7.1</span>  What Is Causality?</a></li>
  <li><a href="#randomized-controlled-trials" id="toc-randomized-controlled-trials" class="nav-link" data-scroll-target="#randomized-controlled-trials"><span class="toc-section-number">7.2</span>  Randomized Controlled Trials</a></li>
  <li><a href="#problems-with-randomization" id="toc-problems-with-randomization" class="nav-link" data-scroll-target="#problems-with-randomization"><span class="toc-section-number">7.3</span>  Problems With Randomization</a></li>
  <li><a href="#difference-in-differences" id="toc-difference-in-differences" class="nav-link" data-scroll-target="#difference-in-differences"><span class="toc-section-number">7.4</span>  Difference-in-Differences</a>
  <ul class="collapse">
  <li><a href="#estimating-dd-in-stata" id="toc-estimating-dd-in-stata" class="nav-link" data-scroll-target="#estimating-dd-in-stata"><span class="toc-section-number">7.4.1</span>  Estimating DD in Stata</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Causal Inference</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>Statistics teachers oftentimes proudly declare to their students that correlation is not causation when emphasizing the idea that just because two things move together that doesn’t mean that one thing is causing the other thing. We’ve discussed examples of this before. So, the question that (at least for me) itched in the back of my mind was “Okay. Well, what <em>is</em> causality then? What does it mean for a thing to cause another thing?”</p>
<p>Our final chapter covers treatment effects/causal inference for policy analysis. Strictly speaking, we could have multiple courses on this. So, as an introduction, this chapter seeks to provide you with the basic philosophy of causal inference, specifically, what it is as a concept, how it’s used in the policy sciences, and how we may use regression to implement basic causal designs for research.</p>
<div class="callout-important callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>In this chapter, I (in addition to the basic philosophy of causality) introduce one of the basic causal inference methods in econometrics and public policy: the difference-in-differences design. It is designed specifically for impact analysis (that is, how one policy affected some specific outcome). Even though it is the last thing we cover, it is <em>not</em> a requirement for your final papers. You may use normal regression to study mere associations if you so choose.</p>
</div>
</div>
<section id="what-is-causality" class="level2" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="what-is-causality"><span class="header-section-number">7.1</span> What Is Causality?</h2>
<p>As I <a href="https://jgreathouse9.github.io/GSUmetricspolicy/correlation.html">mentioned</a> in the chapter on correlation, humans have <em>evolved</em> to think hypothetically. It is how we have survived for as long as we have. Causal inference demands that we imagine another world that we believe could exist, but doesn’t exist. In history, we’d call this a “counterfactual”, so termed because we are talking about a scenario that happened in contrast to observed facts. We as human beings do this all the time.</p>
<ul>
<li><p>What if the North lost the American Civil War? How would the American economy have evolved post 1865 if this happened?</p></li>
<li><p>What if a school kept the same math curriculum instead of implementing a new one?</p></li>
<li><p>How would gun homicide statistics look if a state <em>didn’t</em> pass gun control policies?</p></li>
<li><p>How would Hawaii’s economy have evolved were it never colonized?</p></li>
<li><p>How would New Orleans’ economy have looked if Hurrican Katrina didn’t happen?</p></li>
</ul>
<p>I keep phrasing it as “what if” because that’s <em>exactly</em> what a counterfacual is. A counterfactual, at its heart, is the way a metric, outcome, or construct <em>would have</em> looked in a world where what did happen, did not happen. Thus, a counterfactual is something we can estimate, guess about, and speculate on, but never see in real life. Before we get into how we’d estimate counterfactuals statistically, though, let’s use a more relatable example.</p>
<p>Suppose I’m going to school today. I think the way I take to school (Way A) is quicker than Way B. This gives us a set of two ways to take, <span class="math inline">\(d \in \{0,1\}\)</span> (read as “d in 0 1”), where <span class="math inline">\(d=0\)</span> means we’ve taken Way B and <span class="math inline">\(d=1\)</span> means we’ve taken Way A. Each way we take, of course, is connected to a set of outcomes. The outcomes are just the time that it takes to get to the destination. We may represent the outcomes of each way as <span class="math inline">\(y^A\)</span> and <span class="math inline">\(y^B\)</span>, where naturally <span class="math inline">\(y^A\)</span> is how long it takes if we take my way and <span class="math inline">\(y^B\)</span> is how long it takes if we go the other way. The “treatment effect” of Way A is <span class="math inline">\(\tau = y^A - y^B\)</span>. Here, <span class="math inline">\(\tau\)</span> (the Greek letter “t-ow”) is the difference in minutes between the way it took me by taking my way, and the time it <em>would’ve</em> taken me if I’d taken Way B. In fact, I did this as I wrote this. I used Google Maps to tell me how long the drive from my apartment to Georgia Tech would be. Using the highway it takes 14 minutes. But, one of the options when I avoid highways takes 23 mniutes.</p>
<table class="table">
<thead>
<tr class="header">
<th>Way Taken</th>
<th>Indicator <span class="math inline">\(d\)</span></th>
<th>Commute Time</th>
<th>Outcome <span class="math inline">\(y\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Way A</td>
<td><span class="math inline">\(d=1\)</span></td>
<td><span class="math inline">\(y^A = 14\)</span> min</td>
<td><span class="math inline">\(y = y^A = 14\)</span> min</td>
</tr>
<tr class="even">
<td>Way B</td>
<td><span class="math inline">\(d=0\)</span></td>
<td><span class="math inline">\(y^B = 23\)</span> min</td>
<td><span class="math inline">\(y = y^B = 23\)</span> min</td>
</tr>
<tr class="odd">
<td>Treatment Effect</td>
<td><span class="math inline">\(\tau\)</span></td>
<td><span class="math inline">\(y^A - y^B = -9\)</span> min</td>
<td>N/A</td>
</tr>
</tbody>
</table>
<p>Suppose I do indeed take Way A, as I would, and that it in fact takes 14 minutes. Does this mean the effect of Way A is -9, or, my way being quicker by 9 minutes? No, not exactly. Maybe I do take <span class="math inline">\(y^A\)</span>, but traffic builds and it doesn’t on the other way. Or, maybe <span class="math inline">\(y^A\)</span> still would take 14 minutes, but the other way, <span class="math inline">\(y^B\)</span>, happens to take 20 minutes instead of 23, meaning our treatment effect is now <span class="math inline">\(14-20=-6\)</span>. The problem inherent here is I cannot take both ways at once. I have a choice to make, and once I choose I must commmit to it. I can <em>either</em> take my way or the other way, I can’t do both on the same day at the same time. Thus, because of this choice, I can only guess as to what <span class="math inline">\(y^B\)</span>’s travel time actually would have been for me on that day. Only one outcome exists in reality. Mathematically, we may represent this as <span class="math inline">\(y=dy^{A}+\left(1-d\right)y^B\)</span>. If we take Way A, we get <span class="math inline">\(y=y^A \times 1 +\left(1-1\right)y^B\)</span>, or just <span class="math inline">\(y^A\)</span> since anything multiplied by 0 is just 0 and <span class="math inline">\(y^A \times 1\)</span> is just <span class="math inline">\(y^A\)</span>. If we take Way B, we get <span class="math inline">\(y=y^A \times 0 +\left(1-0\right)y^B\)</span>, or just <span class="math inline">\(y^B\)</span> because now <span class="math inline">\(y^A \times 0=0\)</span> and <span class="math inline">\(\left(1-0\right)y^B\)</span> is just <span class="math inline">\(1 \times y^B\)</span>. This means that the counterfactual is <em>inherently</em> unobservable. Short of time machines where we can peer into alternate universes, the counterfactual is something we have to estimate.</p>
</section>
<section id="randomized-controlled-trials" class="level2" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="randomized-controlled-trials"><span class="header-section-number">7.2</span> Randomized Controlled Trials</h2>
<p>Establishing causality and generating counterfactuals are all about comparisons. Typically, we compare a group of one or more units that did an intervention or policy to units that did not do the same policy. We use regression as a vehicle to facilitate this comparison. Before we do this for a real policy example though, let’s think about how this is done in a (close to) ideal setting.</p>
<p>In medicine, we must test drugs in order to see if they work before we allow them to be used on humans in a broader sense. We use randomized controlled trials to try to establish the efficacy of drugs. A randomzied controlled trial is a form of study design where we, as the reasearchers, assign a treatment at random to a certain number of people or units or entities. Those who get the treatment we call the <em>treatment group</em>, those who do not get it are called the <em>control group</em> (or, sometimes we call the untreated group the <em>donor pool</em>). When we say “random assignment”, we mean that we assign the treatment such that each person has an equal probability of getting the treatment. There are many such way to do this in reality, but at its heart we essentially use a computer to flip a coin across <span class="math inline">\(N\)</span> individuals/units to determine if it gets treatment. If treatment assignment is truly random, this now means that any <em>other</em> covariates that may influence the outcome do not predict treatment status or outcome information.</p>
<p>Say we wish to study the impact of a vaccine on recovery time. We cannot just give the vaccine to some people and not others in a non-random way because maybe other variables are influencing recovery rates. Perhaps those who took the vaccine are younger on average than those who didn’t. Or, maybe they had bettter baseline health characteristics. This means, on average, those who took the vaccine would recover from COVID (say) quicker than the control group, not completely because of the vaccine but because they were already healthier or younger on average compared to the control group. We’d say something is wrong if they <em>didn’t</em> recover quicker. Alternatively, maybe there are just unobserved factors we can’t see which explain why the treatment group did better, to a degree.</p>
<p>When the coin flip decides who gets the vaccine, then in a large enough representative sample, our treatment and control groups are <em>balanced</em> across all confounders, on average. We say “balanced” because when all study participants of all ages, races, and so on are <strong>equally likely</strong> to be given the vaccine or not, the average difference in recovery time can be better attributed to the vaccine instead of other factors such as age. Thus, it is very important to ensure that our control group is balanced across all relevant areas which may affect the outcome. If our treatment and control groups are balanced, we may compute the average treatment effect of the treatment as <span class="math inline">\(\text{ATE}=\frac{1}{N}\sum_{i=1}^{N}y_i^1-y_i^0\)</span>. This is just the average of the raw differences in the outcomes of the treatment group and control group, where <span class="math inline">\(y_i^1\)</span> is the outcomes for all of our treated units (recovery time, in this case) and <span class="math inline">\(y_i^0\)</span> represents the average recovery time for all those in the control group.</p>
<p>To illustrate the idea of balance in a public policy setting, I generate synthetic data on 100 individuals who, at their job, enter some program which may increase income. Individuals are aged from 18 to 50. However, age may correlate with income. Older people tend to have more work/professional experience than younger people, on average. So, simply comparing the outcomes of adults versus the outcomes of a younger group may be ill-advised, as maybe those who make more money and participated in the program would have made more money anyways, without the program, due to different baseline levels of experience due to age. To test this, I iteratively assign some probability of treatment to all of them from <span class="math inline">\(0.05 \leq p \leq 0.5\)</span> in increments of 0.01. We can see, from the GIF below, that when the probability of being treated is <span class="math inline">\(0.5\)</span>, the differences across both age and pre-existing incomes vanishes. The control group is on average a year older than the treatment group, and the income difference between them vanishes to an absolute difference of 54 dollars, where the treatment group makes more than the people who didn’t do the jobs program. So now that we’ve randomized the treatment, we can have people take the program and see how it affects their incomes.</p>
<img src="randomization_balance.gif" alt="Animation" width="680">
</section>
<section id="problems-with-randomization" class="level2" data-number="7.3">
<h2 data-number="7.3" class="anchored" data-anchor-id="problems-with-randomization"><span class="header-section-number">7.3</span> Problems With Randomization</h2>
<p>The central issue with randomization is that there are some interventions (in fact, most of them) that researchers simply cannot randomize. After all, many treatments of interest have explicit assignment mechanisims (i.e., this neighborhood has high crime rates <em>therefore</em> we elect to send more police as a response to crime). Even if the rationale for doing the treatment is not given, sometimes our available set of control units may differ in important ways from the unit that’s treated.</p>
<p>In February of 2023, Turkey had an earthquake. Suppose we’re interested in the effect of <a href="https://apnews.com/article/earthquake-turkey-syria-february-2023-62dba95d0608a3a587ddd2fe5ec39541">this earthquake</a> on the local economic outcomes for the affected cities or the entire country. Well, researchers cannot randomize earthquakes to strike certain cities versus others, and even if we could this would be morally unacceptable. So assuming we were comparing cities in Turkey that were affected to those that weren’t, the affected areas may differ in their baseline characteristics from unaffected areas. For example, <a href="https://www.economist.com/graphic-detail/2023/02/16/poor-areas-suffered-35-times-more-damage-in-turkeys-earthquake">maybe poorer areas</a> were more vulnerable than richer ones. For a cross country comparison, maybe <a href="https://archinect.com/news/article/150422767/strict-building-codes-prevented-a-larger-catastrophe-in-earthquake-prone-taiwan">bulding codes</a> would explain the differences in the effect of the earthquake which, in turn, affect the economic implications for Turkey versus another unexposed nation.</p>
<p>Another example is cannabis legalization. We cannot flip coins to have some states legalize cannabis and others not. Canabis’ legality is decided by the preferences of the legislature. Thus, we run into the problem of selection bias (as in, maybe some states are more likely to legealize cannabis than others). We also run into counfounding biases. If we wish to see how legal cannabis affected alcohol sales for Oregon, then we need to consider what other factors may affect alcohol consumption aside from the policy of interest. That is, Oregon may differ from other states (say, Alabama or Mississippi) on key characteristics that makes the causal comparison unreasonable. Maybe the price of alcohol between Oregon and a set of others states was not similar enough. Maybe Oregon simply had different economic conditions that made alcohol consumption more or less likely. Perhaps cultural factors would lead to higher level of alcohol consumption anyways, absent cannabis legalization. The fact that we cannot randomize means that researchers cannot make plausible the unconfoundedness assumption (or, lack of omitted variable bias) which underlies OLS regression models.</p>
</section>
<section id="difference-in-differences" class="level2" data-number="7.4">
<h2 data-number="7.4" class="anchored" data-anchor-id="difference-in-differences"><span class="header-section-number">7.4</span> Difference-in-Differences</h2>
<p>Even though we cannot randomize all treatments/policies, does this mean that we cannot do policy analysis at all? No.&nbsp;Modern econometrics has developed a slew of methods for doing policy analysis when the intervention of interest simply <em>cannot</em> be subject to a controlled expriment. I now introduce the difference-in-differences method (DD). DD is a method used for panel data. Up until this point, we have presumed that we are working with only one collection of units at one time point. This is called a cross-sectional dataset, where we have <span class="math inline">\(N&gt;1\)</span> units and <span class="math inline">\(T=1\)</span> time periods.</p>
<table class="table">
<thead>
<tr class="header">
<th>Country</th>
<th>Year</th>
<th>Units</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Mexico</td>
<td>2000</td>
<td>1</td>
<td>50</td>
</tr>
<tr class="even">
<td>Guatemala</td>
<td>2000</td>
<td>1</td>
<td>45</td>
</tr>
</tbody>
</table>
<p>The opposite of this is called a time-series dataset, where we have <span class="math inline">\(N=1\)</span> units and <span class="math inline">\(T&gt;1\)</span> time periods.</p>
<table class="table">
<thead>
<tr class="header">
<th>Country</th>
<th>Year</th>
<th>Units</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Mexico</td>
<td>2000</td>
<td>1</td>
<td>50</td>
</tr>
<tr class="even">
<td>Mexico</td>
<td>2001</td>
<td>1</td>
<td>55</td>
</tr>
</tbody>
</table>
<p>A panel dataset is where <span class="math inline">\(N&gt;1\)</span> and <span class="math inline">\(T&gt;1\)</span>.</p>
<table class="table">
<thead>
<tr class="header">
<th>Country</th>
<th>Year</th>
<th>Units</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Mexico</td>
<td>2000</td>
<td>1</td>
<td>50</td>
</tr>
<tr class="even">
<td>Mexico</td>
<td>2001</td>
<td>1</td>
<td>55</td>
</tr>
<tr class="odd">
<td>Guatemala</td>
<td>2000</td>
<td>1</td>
<td>45</td>
</tr>
<tr class="even">
<td>Guatemala</td>
<td>2001</td>
<td>1</td>
<td>50</td>
</tr>
</tbody>
</table>
<p>The DD method uses OLS as a workhorse. Before we get into any of that though, I’d like to explain the basic intuition behind the method. DD asks us, as analysts, to accept a singular condition as plausible: namely, that the intercept adjusted average of our controls is a good enough proxy for how the treated unit’s outcomes would look absent treatment. This is called the “<em>parallel trends assumption</em>”. It means that if the intervention never happened, the trend of our control group would move in the same way as the average of the treated unit. Let’s use Proposition 99 as an example case.</p>
<p>In our case, we have <span class="math inline">\(N=39\)</span> and <span class="math inline">\(T=31\)</span>. Here, each unit is indexed to the letter <span class="math inline">\(i\)</span>. For our purposes, <span class="math inline">\(i=1\)</span> is California, and the other <span class="math inline">\(i=\{2 \ldots 39 \}\)</span> units are the control states. Each year <span class="math inline">\(t\)</span> is indexed to the years 1970 through 2000, respectively. In panel data, each of the units corresponds to only <em>one</em> time period. Each of the 39 units, in this case, has 31 rows.</p>
<div class="cell" data-engine="jupyter" data-execution_count="2">
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="treatmenteffects_files/figure-html/cell-3-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Here, we plot the cigarette consumption of California versus the average of controls, as well as the individual outcomes for the control states. We can see that in 1970, California is fairly similar to the average of the other 38 untreated states. However as the years progress, the average trend of control units slopes upward by a lot, whereas Califronia’s smoking trends grew relatively little and begin to precipitously fall in 1975 and for all years after. When we look at the plot on the right, this makes a little more sense: there are a few states (Kentucky and New Hampshire) at the top of the plot whose tobacco sales drastically increased between 1970 and the mid 1970s.</p>
<p>As I mentioned above, the main workhorse of DID is OLS regression. I will give Stata and R code below, so we can streamline this process, but I think a broken down sense of what’s going on helps <em>a lot</em> to understand what’s happening. We begin by fitting:</p>
<p><span class="math display">\[
y_{1t} = \beta_0 + \beta_{1}\bar{y}_{\text{co},t} \quad \text{s.t. } \beta_1 = 1.
\]</span></p>
<p>This is not as scary as it seems. All this is is OLS regression, where we seek the line that minimizes the prediction error between our independent variables and our outcome. Our dependent variable in this regression model, <span class="math inline">\(y_{1t}\)</span> is the pre-intervention outcomes of our treated unit (California) and our independent variables are a constant and the year-wise average of the 38 control states, <span class="math inline">\(\bar{y}_{\text{co},t}\)</span>. Notice here how we force the coefficient for the average of controls to be 1. Why? Well, the parallel trends assumption. DD presumes that a pure average of our controls, adjusted only by an intercept, is a good enough proxy for our counterfactual. The coefficient <span class="math inline">\(\beta_1\)</span> must be 1 because if it were not, the observed unit would not be parallel anymore to a pure average of controls. The constant here is roughly <span class="math inline">\(-14\)</span>. After we estimate this model, we predict the remaining values for the post-intervention period. I plot the results of this regression model below (for the moment look only at the left hand side of the plot).</p>
<div class="cell" data-engine="jupyter" data-execution_count="3">
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="treatmenteffects_files/figure-html/cell-4-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Well, what do we see here? We see the counterfactual produced by DID. In this case, for DID, the counterfactual is simply the average of the control units minus 14. We calcluate the treatment effect for California as <span class="math inline">\(ATT = \frac{1}{T_1 - T_0} \sum_{T_0 +1}^{T} (y_{1t} - \hat{y}_{1t})\)</span>, where <span class="math inline">\(T_0\)</span> and <span class="math inline">\(T_1\)</span> respectively are the number of pre and post intervention periods. The estimates suggest that Prop 99 decreased tobacco consumption by about 27.349 packs per capita, with a confidence interval of <span class="math inline">\(\left[-32.522,-22.177\right]\)</span>.</p>
<p>Okay, now we have this counterfactual. But is it a good one? We can begin by recalling our metric of fit, the RMSE. In this case, think of the RMSE as a metric of parallel-ness. The smaller the RMSE is, the better our pre-intervention predictions are. The bigger it is, the worse our pre-intervention predictions are. This matters because if we have good pre-intervention model predictions, we’re likely to have better post-intervention counterfactual predictions. If we have worse pre-intervention model predictions, we are less likely to take seriously the predicted counterfactual. Beyond this, we can look at the plotted predictions (again, focus on the left hand side plot for now). Do the predictions of DD look close to the values of the treated unit? Not really, to me. The DID counterfactual underpredicts the true values for California in the pre-intervention period from around 1970 to 1975. Beyond this, it also misses the true values for the years of 1980 through 1988. This is particularly bad because if your predictions diverge significantly from the treated unit’s observed values in the years right before the intervention takes place, why would we think the post-intervnetion predictions are valid? No doubt, the reason for such bad predictions are the fact that we included all 38 control units. As we’ve discussed, outliers will significantly bias an average. This means that we must be smart about which units we are comparing California to, since if we include poor control units, we will have poor predictions.</p>
<p>What if we used a different contrrol group though? Say I use Montana, Colorado, Nevada, Connecticut.</p>
<div class="cell" data-engine="jupyter" data-execution_count="4">
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="treatmenteffects_files/figure-html/cell-5-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Well now! This certainly looks a lot more parallel than when we used all of our control units!! When we use the limited set of controls, our treatment effect becomes -13.647, with a confidence interval of <span class="math inline">\(\left[-14.549,-12.745\right]\)</span>. Think of how big of a reduction this is: when we used all control units, we come up with an effect of 27, but when we use a more limited pool of controls, we get an effect of around 14. That’s pretty much a reduction of 100% in terms of the average treatment effect! In addition to “looking” more parallel, the parallel trends bias, as measured by the RMSE, shrinks by <strong>140%</strong>. Below, I will show Stata code as to how we can get these estimates a lot quicker than by doing it in this way, but I hope that explaining DD as a regression estimator helps build intuition as to how it works in practice.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>As with OLS, rarely will you do DD in the manner I’ve described it above. However, I feel that Stata and R, through their excellent computing capabilities, can largely obscure what’s going on when we use <code>reg</code> or <code>didregress</code>. Also, we can extend DD to instances where many units are treated at different time points. However, for the introductory level, I think DD with a single treated unit is more than adequate as a starting point.</p>
</div>
</div>
<section id="estimating-dd-in-stata" class="level3" data-number="7.4.1">
<h3 data-number="7.4.1" class="anchored" data-anchor-id="estimating-dd-in-stata"><span class="header-section-number">7.4.1</span> Estimating DD in Stata</h3>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./ols.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">OLS Explained</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
  </div>
</nav>
</div> <!-- /content -->



</body></html>
