<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Econometrics for Policy Analysis - 7&nbsp; Causal Inference</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./ols.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Causal Inference</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Econometrics for Policy Analysis</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Syllabus: PMAP 4041, Fall 2024</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./module1.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Data and Policy Studies</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Mathematics and Econometric Theory</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./basicprob.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Basic Probability Theory</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stataintro.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Introduction to Stata</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./correlation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Correlation and Association</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ols.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">OLS Explained</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./treatmenteffects.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Causal Inference</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">Applied Research Methods</span>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#what-is-causality" id="toc-what-is-causality" class="nav-link active" data-scroll-target="#what-is-causality"><span class="toc-section-number">7.1</span>  What Is Causality?</a></li>
  <li><a href="#randomized-controlled-trials" id="toc-randomized-controlled-trials" class="nav-link" data-scroll-target="#randomized-controlled-trials"><span class="toc-section-number">7.2</span>  Randomized Controlled Trials</a></li>
  <li><a href="#problems-with-randomization" id="toc-problems-with-randomization" class="nav-link" data-scroll-target="#problems-with-randomization"><span class="toc-section-number">7.3</span>  Problems With Randomization</a></li>
  <li><a href="#difference-in-differences" id="toc-difference-in-differences" class="nav-link" data-scroll-target="#difference-in-differences"><span class="toc-section-number">7.4</span>  Difference-in-Differences</a>
  <ul class="collapse">
  <li><a href="#dd-setup" id="toc-dd-setup" class="nav-link" data-scroll-target="#dd-setup"><span class="toc-section-number">7.4.1</span>  DD Setup</a></li>
  <li><a href="#introducing-parallel-trends" id="toc-introducing-parallel-trends" class="nav-link" data-scroll-target="#introducing-parallel-trends"><span class="toc-section-number">7.4.2</span>  Introducing Parallel Trends</a></li>
  <li><a href="#quality-of-parallel-trends" id="toc-quality-of-parallel-trends" class="nav-link" data-scroll-target="#quality-of-parallel-trends"><span class="toc-section-number">7.4.3</span>  Quality of Parallel Trends</a></li>
  <li><a href="#estimating-dd" id="toc-estimating-dd" class="nav-link" data-scroll-target="#estimating-dd"><span class="toc-section-number">7.4.4</span>  Estimating DD</a></li>
  <li><a href="#a-second-pass-at-parallel-trends-quality" id="toc-a-second-pass-at-parallel-trends-quality" class="nav-link" data-scroll-target="#a-second-pass-at-parallel-trends-quality"><span class="toc-section-number">7.4.5</span>  A Second Pass at Parallel Trends Quality</a></li>
  <li><a href="#alternate-control-group" id="toc-alternate-control-group" class="nav-link" data-scroll-target="#alternate-control-group"><span class="toc-section-number">7.4.6</span>  Alternate Control Group</a></li>
  <li><a href="#streamlining-dd-in-econometrics-software" id="toc-streamlining-dd-in-econometrics-software" class="nav-link" data-scroll-target="#streamlining-dd-in-econometrics-software"><span class="toc-section-number">7.4.7</span>  Streamlining DD in Econometrics Software</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Causal Inference</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>Statistics teachers oftentimes proudly declare to their students that correlation is not causation when emphasizing the idea that just because two things move together that doesn’t mean that one thing is causing the other thing. We’ve discussed examples of this before. So, the question that (at least for me) itched in the back of my mind was “Okay. Well, what <em>is</em> causality then? What does it mean for a thing to cause another thing?”</p>
<p>Our final chapter covers treatment effects/causal inference for policy analysis. Strictly speaking, we could have multiple courses on this. So, as an introduction, this chapter seeks to provide you with the basic philosophy of causal inference, specifically, what it is as a concept, how it’s used in the policy sciences, and how we may use regression to implement basic causal designs for research.</p>
<div class="callout-important callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>In this chapter, I (in addition to the basic philosophy of causality) introduce one of the basic causal inference methods in econometrics and public policy: the difference-in-differences design. It is designed specifically for impact analysis (that is, how one policy affected some specific outcome). Even though it is the last thing we cover, it is <em>not</em> a requirement for your final papers. You may use normal regression to study mere associations if you so choose.</p>
</div>
</div>
<section id="what-is-causality" class="level2" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="what-is-causality"><span class="header-section-number">7.1</span> What Is Causality?</h2>
<p>As I <a href="https://jgreathouse9.github.io/GSUmetricspolicy/correlation.html">mentioned</a> in the chapter on correlation, humans have <em>evolved</em> to think hypothetically. It is how we have survived for as long as we have. Causal inference demands that we imagine another world that we believe could exist, but doesn’t exist. In history, we’d call this a “counterfactual”, so termed because we are talking about a fictional scenario that happened in contrast to observed facts. We as human beings do this all the time.</p>
<ul>
<li><p>How would the American economy have evolved post 1860 if the Civil War never happened?</p></li>
<li><p>What if a school did a new math curriculum? Would math scores improve?</p></li>
<li><p>How would gun homicide statistics look, 6 months from now, if a state <em>didn’t</em> pass gun control policies?</p></li>
<li><p>How would a grocery store’s in store sales have evolved if it didn’t implement all self checkout scanners?</p></li>
<li><p>Did Nebraska’s repeal of the tampon tax affect tampon use? How would tampon sales have evolved if Nebraska didn’t get rid of the tax?</p></li>
<li><p>How would New Orleans’ outward migration have looked if Hurricane Katrina didn’t happen?</p></li>
</ul>
<p>A counterfactual, at its heart, is the way a metric, outcome, or construct <em>would have</em> looked in a world where what did happen (some treatment, policy, or intervention), did not happen. However, we get but one copy of reality. We can’t literally look at the United States where the Civil War happened (the reality we have) and one where it didn’t happen (not that we’d really want to, by the way). We can’t have a school with one grade level has two math curriculums (the current one and new one) at once, and even if we could, how could we know the new curriculum is the driver of grades instead of something else? We can’t see the same city that has banned guns and not done so, or a state that both taxes and doesn’t tax tampons. Thus, counterfactuals are things we can estimate, guess about, and speculate on, but never see in real life. Before we get into how we’d estimate counterfactuals statistically, though, let’s use a more relatable example.</p>
<p>Suppose I’m going to school today. I think the way I take to school (Way A) is quicker than Way B. This gives us a set of two ways to take, \(d \in \{0,1\}\) (read as “d in 0 1”), where \(d=0\) means we’ve taken Way B and \(d=1\) means we’ve taken Way A. The outcome of interest \(y\) is the commute tone associated with each way we take, Each way we take, expressed formally as \(d \mapsto y\left(d\right)\), or our commute time being a function of the road we choose. We may represent the outcomes of each way as \(y^A\) and \(y^B\), where naturally \(y^A\) is how long it takes if we take my way and \(y^B\) is how long it takes if we go the other way. The “treatment effect” of Way A is \(\tau = y^A - y^B\). Here, \(\tau\) (the Greek letter “t-ow”) is the difference in minutes between the way it took me by taking my way, and the time it <em>would’ve</em> taken me if I’d taken Way B. In fact, I did this as I wrote this. I used Google Maps to tell me how long the drive from my apartment to Georgia Tech would be. Using the highway it takes 14 minutes. But, one of the options when I avoid highways takes 23 minutes.</p>
<table class="table">
<thead>
<tr class="header">
<th>Way Taken</th>
<th>Indicator <span class="math inline">\(d\)</span></th>
<th>Commute Time</th>
<th>Outcome <span class="math inline">\(y\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Way A</td>
<td><span class="math inline">\(d=1\)</span></td>
<td><span class="math inline">\(y^A = 14\)</span> min</td>
<td><span class="math inline">\(y = y^A = 14\)</span> min</td>
</tr>
<tr class="even">
<td>Way B</td>
<td><span class="math inline">\(d=0\)</span></td>
<td><span class="math inline">\(y^B = 23\)</span> min</td>
<td><span class="math inline">\(y = y^B = 23\)</span> min</td>
</tr>
<tr class="odd">
<td>Treatment Effect</td>
<td><span class="math inline">\(\tau\)</span></td>
<td><span class="math inline">\(y^A - y^B = -9\)</span> min</td>
<td>N/A</td>
</tr>
</tbody>
</table>
<p>Suppose I do indeed take Way A, as I would, and that it in fact takes 14 minutes. Does this mean the effect of Way A is -9, or, my way being quicker by 9 minutes? No, not exactly. Maybe I do take \(y^A\), but traffic builds and it doesn’t on the other way. Or, maybe \(y^A\) still would take 14 minutes, but the other way, \(y^B\), happens to take 20 minutes instead of 23, meaning our treatment effect is now \(14-20=-6\). The problem inherent here is I cannot take both ways at once. I have a choice to make, and once I choose I must commmit to it. I can <em>either</em> take my way or the other way, I can’t do both on the same day at the same time. Thus, because of this choice, I can only guess as to what \(y^B\)’s travel time actually would have been for me on that day. Only one outcome exists in reality. Mathematically, we may represent this as <span class="math inline">\(y=dy^{A}+\left(1-d \right)y^B\)</span>. If we take Way A, we get \(y=y^A \times 1 +\left(1-1\right)y^B\), or just \(y^A\) since anything multiplied by 0 is just 0 and \(y^A \times 1\) is just \(y^A\). If we take Way B, we get \(y=y^A \times 0 +\left(1-0\right)y^B\), or just \(y^B\) because now \(y^A \times 0=0\) and \(\left(1-0\right)y^B\) is just \(1 \times y^B\). This means that the counterfactual is <em>inherently</em> unobservable. Short of time machines where we can peer into alternate universes, the counterfactual is something we have to estimate.</p>
</section>
<section id="randomized-controlled-trials" class="level2" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="randomized-controlled-trials"><span class="header-section-number">7.2</span> Randomized Controlled Trials</h2>
<p>Establishing causality and generating counterfactuals are all about comparisons. Typically, we compare a group of one or more units that did an intervention or policy to units that did not do the same policy. We use regression as a vehicle to facilitate this comparison. Before we do this for a real policy example though, let’s think about how this is done in a (close to) ideal setting.</p>
<p>In medicine, we must test drugs in order to see if they work before we allow them to be used on humans in a broader sense. We use randomized controlled trials to try to establish the efficacy of drugs. A randomzied controlled trial is a form of study design where we, as the reasearchers, assign a treatment at random to a certain number of people or units or entities. Those who get the treatment we call the <em>treatment group</em>, those who do not get it are called the <em>control group</em> (or, sometimes we call the untreated group the <em>donor pool</em>). When we say “random assignment”, we mean that we assign the treatment such that each person has an equal probability of getting the treatment. There are many such way to do this in reality, but at its heart we essentially use a computer to flip a coin across \(N\) individuals/units to determine if it gets treatment. If treatment assignment is truly random, this now means that any <em>other</em> covariates that may influence the outcome do not predict treatment status or outcome information.</p>
<p>Say we wish to study the impact of a vaccine on recovery time. We cannot just give the vaccine to some people and not others in a non-random way because maybe other variables are influencing recovery rates. Perhaps those who took the vaccine are younger on average than those who didn’t. Or, maybe they had bettter baseline health characteristics. This means, on average, those who took the vaccine would recover from COVID (say) quicker than the control group, not completely because of the vaccine but because they were already healthier or younger on average compared to the control group. We’d say something is wrong if they <em>didn’t</em> recover quicker. Alternatively, maybe there are just unobserved factors we can’t see which explain why the treatment group did better, to a degree.</p>
<p>When the coin flip decides who gets the vaccine, then in a large enough representative sample, our treatment and control groups are <em>balanced</em> across all confounders, on average. We say “balanced” because when all study participants of all ages, races, and so on are <strong>equally likely</strong> to be given the vaccine or not, the average difference in recovery time can be better attributed to the vaccine instead of other factors such as age. Thus, it is very important to ensure that our control group is balanced across all relevant areas which may affect the outcome. If our treatment and control groups are balanced, we may compute the average treatment effect of the treatment as <span class="math inline">\(\text{ATE}=\frac{1}{N}\sum_{i=1}^{N}y_i^1-y_i^0\)</span>. This is just the average of the raw differences in the outcomes of the treatment group and control group, where \(y_i^1\) is the observed outcomes for all of our treated units (recovery time, in this case) and \(y_i^0\) represents the average recovery time for all those in the control group.</p>
<p>To illustrate the idea of balance in a public policy setting, I generate synthetic data on 100 individuals who, at their job, enter some program which may increase income. Individuals are aged from 18 to 50. However, age may correlate with income. Older people tend to have more work/professional experience than younger people, on average. So, simply comparing the outcomes of adults versus the outcomes of a younger group may be ill-advised, as maybe those who make more money and participated in the program would have made more money anyways, without the program, due to different baseline levels of experience due to age. To test this, I iteratively assign some probability of treatment to all of them from \(0.05 \leq p \leq 0.5\) in increments of 0.01. We can see, from the GIF below, that when the probability of being treated is \(0.5\), the differences across both age and pre-existing incomes vanishes. The control group is on average a year older than the treatment group, and the income difference between them vanishes to an absolute difference of 54 dollars, where the treatment group makes more than the people who didn’t do the jobs program. So now that we’ve randomized the treatment, we can have people take the program and see how it affects their incomes.</p>
<img src="randomization_balance.gif" alt="Animation" width="680">
</section>
<section id="problems-with-randomization" class="level2" data-number="7.3">
<h2 data-number="7.3" class="anchored" data-anchor-id="problems-with-randomization"><span class="header-section-number">7.3</span> Problems With Randomization</h2>
<p>The central issue with randomization is that there are some interventions (in fact, most of them) that researchers simply cannot randomize. After all, many treatments of interest have explicit assignment mechanisims (i.e., this neighborhood has high crime rates <em>therefore</em> we elect to send more police as a response to crime). Even if the rationale for doing the treatment is not given, sometimes our available set of control units may differ in important ways from the unit that’s treated.</p>
<p>In February of 2023, Turkey had an earthquake. Suppose we’re interested in the effect of <a href="https://apnews.com/article/earthquake-turkey-syria-february-2023-62dba95d0608a3a587ddd2fe5ec39541">this earthquake</a> on the local economic outcomes for the affected cities or the entire country. Well, researchers cannot randomize earthquakes to strike certain cities versus others, and even if we could this would be morally unacceptable. So assuming we were comparing cities in Turkey that were affected to those that weren’t, the affected areas may differ in their baseline characteristics from unaffected areas. For example, <a href="https://www.economist.com/graphic-detail/2023/02/16/poor-areas-suffered-35-times-more-damage-in-turkeys-earthquake">maybe poorer areas</a> were more vulnerable than richer ones. For a cross country comparison, maybe <a href="https://archinect.com/news/article/150422767/strict-building-codes-prevented-a-larger-catastrophe-in-earthquake-prone-taiwan">bulding codes</a> would explain the differences in the effect of the earthquake which, in turn, affect the economic implications for Turkey versus another unexposed nation.</p>
<p>Another example is cannabis legalization. We cannot flip coins to have some states legalize cannabis and others not. Canabis’ legality is decided by the preferences of the legislature. Thus, we run into the problem of selection bias (as in, maybe some states are more likely to legealize cannabis than others). We also run into counfounding biases. If we wish to see how legal cannabis affected alcohol sales for Oregon, then we need to consider what other factors may affect alcohol consumption aside from the policy of interest. That is, Oregon may differ from other states (say, Alabama or Mississippi) on key characteristics that makes the causal comparison unreasonable. Maybe the price of alcohol between Oregon and a set of others states was not similar enough. Maybe Oregon simply had different economic conditions that made alcohol consumption more or less likely. Perhaps cultural factors would lead to higher level of alcohol consumption anyways, absent cannabis legalization. The fact that we cannot randomize means that researchers cannot make plausible the unconfoundedness assumption (or, lack of omitted variable bias) which underlies OLS regression models.</p>
</section>
<section id="difference-in-differences" class="level2" data-number="7.4">
<h2 data-number="7.4" class="anchored" data-anchor-id="difference-in-differences"><span class="header-section-number">7.4</span> Difference-in-Differences</h2>
<p>Even though we cannot randomize all treatments/policies, does this mean that we cannot do policy analysis at all? No.&nbsp;Modern econometrics has developed a slew of <a href="https://raw.githubusercontent.com/jgreathouse9/jgreathouse9.github.io/refs/heads/master/file.txt">methods</a> for doing policy analysis when the intervention of interest simply <em>cannot</em> be subject to a controlled expriment. I now introduce the difference-in-differences method (DD), using Proposition 99 as an example case. DD is a method used for panel data.</p>
<section id="dd-setup" class="level3" data-number="7.4.1">
<h3 data-number="7.4.1" class="anchored" data-anchor-id="dd-setup"><span class="header-section-number">7.4.1</span> DD Setup</h3>
<p>To implement DD, we need a few key ingredients: First, we need a treatment of interest with a clear before and after point. In our case, Proposition 99 was passed in 1988, and enacted in 1989. So, we have a clearly defined treatment point. We also need at least one unit that experienced the treatment, and at least one that doesn’t experience the treatment. In our case, we have \(N=39\) units. Here, each unit is indexed to the letter \(i\). For our purposes, \(i=1\) is California, and the other \(i=\{2 \ldots 39 \}\) units are the control states. and \(T=31\) time periods, where, respectively, <span class="math inline">\(T_0=19\)</span> refelcts the number of preintervention periods from 1970 to 1988 and <span class="math inline">\(T_1=12\)</span> reflects the number of post-intervention periods. In panel data, each of the units corresponds to only <em>one</em> time period. Each of the 39 units, in this case, has 31 rows.</p>
</section>
<section id="introducing-parallel-trends" class="level3" data-number="7.4.2">
<h3 data-number="7.4.2" class="anchored" data-anchor-id="introducing-parallel-trends"><span class="header-section-number">7.4.2</span> Introducing Parallel Trends</h3>
<p>Unlike in a setting where we have a randomized trial, our control group will not be balanced on covariates/outcomes with the treatment group in the pretreatment period. That is, if we take the average of our treatment and control group outcomes in the pre policy period, the numbers will likely not have the same or very close values as they did in the GIF above when I demonstrated randomization. But that’s okay: what if we don’t need the means to be balanced exactly? What if we just need for the <em>trends</em> of the groups to be similar to one another?</p>
<p>DD asks us, as analysts, to accept a singular condition as plausible: namely, that the intercept adjusted average of our controls is a good enough proxy for how the treated unit’s outcomes would look absent treatment. This is called the “<em>parallel trends assumption</em>”. It means that if the intervention never happened, the average trend of our control group would move in the same way as the average of the treated unit. The parallel trends assumption is inherently untestable, since we only <em>actually</em> observe <span class="math inline">\(y=dy^{1}+\left(1-d \right)y^0\)</span>. However, the key we shall focus on is the parallel-ness in the pre-intervention period, since this is the only time period we observe all of our units without treatment.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>I will use “parallel trends”, “parallel pre-trends”, and other words to that effect interchangeably.</p>
</div>
</div>
</section>
<section id="quality-of-parallel-trends" class="level3" data-number="7.4.3">
<h3 data-number="7.4.3" class="anchored" data-anchor-id="quality-of-parallel-trends"><span class="header-section-number">7.4.3</span> Quality of Parallel Trends</h3>
<p>For parallel trends to hold, the control group must be as similar as possible to the treatment group before the treatment was done.</p>
<div class="goals">
<div class="goals-header">
<p>Why?</p>
</div>
<div class="goals-container">
<p>The quality of our controls is what we use to build our counterfactual. I wrote above that causal inference is predicated on comparisons. For example, let’s say Honolulu implements an anti-crime policy. Can we use New Orleans or St.&nbsp;Louis as comparison cities? Likely not. The latter two are high crime areas, being regularly distinguished in national crime statistics for having high murder rates and other violent crimes. They are heavily urbanized places, with vastly different cultural makeups, climates, and settings. Therefore, we wouldn’t expect for these two cities to be sufficiently comparable enough to Honolulu to warrant a good causal comparison.</p>
</div>
</div>
<p>A good first way to assess the quality of parallel pre-intervention trends is to simply plot the average control outcomes and the average treatment outcomes and look at how similar their trends are in the pre-intervention period.</p>
<div class="cell" data-engine="jupyter" data-execution_count="2">
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="treatmenteffects_files/figure-html/cell-3-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Here, we plot the cigarette consumption of California versus the average of control states. We can see in 1970, California is fairly similar to the control average. In fact, the average of controls and California both grow in their consumption rates up until 1976. However as the years progress, the average trend of controls grows at a much faster rate than California’s. California’s smoking trends grew relatively little and begin to precipitously fall in and after 1976, whereas the control group’s trend has much higher rates of smoking. We can also investigate the quality of parallel pre-trends empirically without needing to use graphical methods, as we will show below.</p>
</section>
<section id="estimating-dd" class="level3" data-number="7.4.4">
<h3 data-number="7.4.4" class="anchored" data-anchor-id="estimating-dd"><span class="header-section-number">7.4.4</span> Estimating DD</h3>
<p>As one might expect, the main workhorse of DD is simply OLS regression, the topic of our previous chapter. I will give Stata and R code below so we can streamline DD estimation, but I think it helps <em>a lot</em> to understand what’s happening from the perspective of regression at first.</p>
<p>To estimate basic DD models, we seek the line that minimizes the prediction error between our independent variables and our outcome. However in this case, our outcome and predictors are special. Our dependent variable in this regression model, <span class="math inline">\(y_{1t}\)</span>, is the pre-intervention outcomes of our treated unit, California. Our independent variable is the year-wise pre-intervention average of the 38 control states, <span class="math inline">\(\bar{y}_{\text{co},t}\)</span>. To show you that we’re not speaking about abstract concepts, below I show the dataset we’d use to do DD with. We index the year to the outcomes of California and the average of its controls.</p>
<div class="cell" data-engine="jupyter" data-execution_count="3">
<div class="cell-output cell-output-display">
<table class="table table-sm table-striped">
<caption>DD Dataset</caption>
<thead>
<tr class="header">
<th style="text-align: right;">Year</th>
<th style="text-align: right;">California</th>
<th style="text-align: right;">Control Group Mean</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">1970</td>
<td style="text-align: right;">123</td>
<td style="text-align: right;">120.08</td>
</tr>
<tr class="even">
<td style="text-align: right;">1971</td>
<td style="text-align: right;">121</td>
<td style="text-align: right;">123.86</td>
</tr>
<tr class="odd">
<td style="text-align: right;">1972</td>
<td style="text-align: right;">123.5</td>
<td style="text-align: right;">129.18</td>
</tr>
<tr class="even">
<td style="text-align: right;">1973</td>
<td style="text-align: right;">124.4</td>
<td style="text-align: right;">131.54</td>
</tr>
<tr class="odd">
<td style="text-align: right;">1974</td>
<td style="text-align: right;">126.7</td>
<td style="text-align: right;">134.67</td>
</tr>
<tr class="even">
<td style="text-align: right;">1975</td>
<td style="text-align: right;">127.1</td>
<td style="text-align: right;">136.93</td>
</tr>
<tr class="odd">
<td style="text-align: right;">1976</td>
<td style="text-align: right;">128</td>
<td style="text-align: right;">141.26</td>
</tr>
<tr class="even">
<td style="text-align: right;">1977</td>
<td style="text-align: right;">126.4</td>
<td style="text-align: right;">141.09</td>
</tr>
<tr class="odd">
<td style="text-align: right;">1978</td>
<td style="text-align: right;">126.1</td>
<td style="text-align: right;">140.47</td>
</tr>
<tr class="even">
<td style="text-align: right;">1979</td>
<td style="text-align: right;">121.9</td>
<td style="text-align: right;">138.09</td>
</tr>
<tr class="odd">
<td style="text-align: right;">1980</td>
<td style="text-align: right;">120.2</td>
<td style="text-align: right;">138.09</td>
</tr>
<tr class="even">
<td style="text-align: right;">1981</td>
<td style="text-align: right;">118.6</td>
<td style="text-align: right;">137.99</td>
</tr>
<tr class="odd">
<td style="text-align: right;">1982</td>
<td style="text-align: right;">115.4</td>
<td style="text-align: right;">136.29</td>
</tr>
<tr class="even">
<td style="text-align: right;">1983</td>
<td style="text-align: right;">110.8</td>
<td style="text-align: right;">131.25</td>
</tr>
<tr class="odd">
<td style="text-align: right;">1984</td>
<td style="text-align: right;">104.8</td>
<td style="text-align: right;">124.9</td>
</tr>
<tr class="even">
<td style="text-align: right;">1985</td>
<td style="text-align: right;">102.8</td>
<td style="text-align: right;">123.12</td>
</tr>
<tr class="odd">
<td style="text-align: right;">1986</td>
<td style="text-align: right;">99.7</td>
<td style="text-align: right;">120.59</td>
</tr>
<tr class="even">
<td style="text-align: right;">1987</td>
<td style="text-align: right;">97.5</td>
<td style="text-align: right;">117.59</td>
</tr>
<tr class="odd">
<td style="text-align: right;">1988</td>
<td style="text-align: right;">90.1</td>
<td style="text-align: right;">113.82</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>We are, in effect, exploiting the correlations between the average of controls and the treated unit to produce a counterfactual. After all, we would imagine that if the average of controls is similar in trend to that of the treated unit, then this average is likely similar to the treated until on unobserved factors as well. So, if the treated unit and control group both have very similar trends in the pre-intervention period, all we now need us a time-trend to account for the time specific differences, captured by our intercept. The simple DD model looks like</p>
<p><span class="math display">\[
y_{1t} = \beta_{1}\bar{y}_{\text{co},t} + \beta_0 \quad \text{s.t. } \beta_1 = 1.
\]</span></p>
<p>As promised, our dependent variable is the outcomes for unit <span class="math inline">\(i=1\)</span>. Our independent variables are the average of our control unit outcomes, and an intercept (which we’re estimating). Notice here how we force the coefficient for the average of controls to be 1.</p>
<div class="goals">
<div class="goals-header">
<p>Why?</p>
</div>
<div class="goals-container">
<p>DD presumes that a <em>pure</em> average of our controls is a good enough proxy for our counterfactual. In other words, in the DD world, all of our control units are treated as equally valid for predicting the counterfactual. So, to have the time-intercept reflect the pre-intervention difference between the pure arithmetic average of controls versus a weighted average of controls, <span class="math inline">\(\beta_{1}\)</span> must be equal to 1. If we multiplied it by some other value, we’d be using a <em>weighted</em> average, not an arithmetic average.</p>
</div>
</div>
<p>After we estimate this model (again <em>just</em> for the preintervention period), we predict the remaining values for the post-intervention period. How do we do the prediction, by the way? Well, it’s easy! We already know what <span class="math inline">\(\beta_{1}\)</span> is, that’s just the mean of our control group. So now as per the model above, we only need to estimate <span class="math inline">\(\beta_{0}\)</span>. Once we have <span class="math inline">\(\beta_{0}\)</span>, we add or subtract whatever that value is to each value of the mean of controls! The constant here for the intercept term is roughly <span class="math inline">\(14.359\)</span>. I plot the results of this regression model below. I also use a table to compare the observed values of the treated unit to the values of the DD counterfactual.</p>
<div class="cell" data-engine="jupyter" data-execution_count="4">
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="treatmenteffects_files/figure-html/cell-5-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<table class="table table-sm table-striped">
<caption>DD Predictions</caption>
<thead>
<tr class="header">
<th style="text-align: right;">Year</th>
<th style="text-align: right;">California</th>
<th style="text-align: right;">DD California</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">1989</td>
<td style="text-align: right;">82.4</td>
<td style="text-align: right;">95.304</td>
</tr>
<tr class="even">
<td style="text-align: right;">1990</td>
<td style="text-align: right;">77.8</td>
<td style="text-align: right;">91.307</td>
</tr>
<tr class="odd">
<td style="text-align: right;">1991</td>
<td style="text-align: right;">68.7</td>
<td style="text-align: right;">89.983</td>
</tr>
<tr class="even">
<td style="text-align: right;">1992</td>
<td style="text-align: right;">67.5</td>
<td style="text-align: right;">89.036</td>
</tr>
<tr class="odd">
<td style="text-align: right;">1993</td>
<td style="text-align: right;">63.4</td>
<td style="text-align: right;">88.336</td>
</tr>
<tr class="even">
<td style="text-align: right;">1994</td>
<td style="text-align: right;">58.6</td>
<td style="text-align: right;">87.759</td>
</tr>
<tr class="odd">
<td style="text-align: right;">1995</td>
<td style="text-align: right;">56.4</td>
<td style="text-align: right;">88.799</td>
</tr>
<tr class="even">
<td style="text-align: right;">1996</td>
<td style="text-align: right;">54.5</td>
<td style="text-align: right;">86.825</td>
</tr>
<tr class="odd">
<td style="text-align: right;">1997</td>
<td style="text-align: right;">53.8</td>
<td style="text-align: right;">87.43</td>
</tr>
<tr class="even">
<td style="text-align: right;">1998</td>
<td style="text-align: right;">52.3</td>
<td style="text-align: right;">86.599</td>
</tr>
<tr class="odd">
<td style="text-align: right;">1999</td>
<td style="text-align: right;">47.2</td>
<td style="text-align: right;">83.236</td>
</tr>
<tr class="even">
<td style="text-align: right;">2000</td>
<td style="text-align: right;">41.6</td>
<td style="text-align: right;">77.775</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Well, what do we see here? We see the counterfactual produced by DID, using all 38 controls. As promised, the counterfactual predicted by DID is simply the original average of the control units minus 14.359! Seriously, that’s all it is.</p>
<p>Now that we’ve predicted our counterfactial, we now calculate the treatment effect for California. We calculate the average treatment effect on the treated unit as</p>
<p><span class="math display">\[
\text{ATT} = \frac{1}{T_1 - T_0} \sum_{T_0 +1}^{T} (y_{1t} - \hat{y}_{1t}),
\]</span></p>
<p>or the average of the differences between what we in fact observed (California under treatment) and what we did not observe (California’s counterfactual smoking outcomes predicted by DD). The ATT suggests that Proposition 99 decreased tobacco consumption by about 27.349 packs per capita, with a 95 percent confidence interval of <span class="math inline">\(\left[-32.522,-22.177\right]\)</span>.</p>
</section>
<section id="a-second-pass-at-parallel-trends-quality" class="level3" data-number="7.4.5">
<h3 data-number="7.4.5" class="anchored" data-anchor-id="a-second-pass-at-parallel-trends-quality"><span class="header-section-number">7.4.5</span> A Second Pass at Parallel Trends Quality</h3>
<p>Okay, now we have this counterfactual. But is it a good one? How can we tell if the counterfactual is plausible here? Looking at graphics is fine, but how can we statistically evaluate if the DD model is a good one? We can begin by recalling a metric of fit, the RMSE. As before, the RMSE represents the normalized average error squared between our observed values and our predicted values.</p>
<p>In this case though, think of the RMSE as a metric of parallel-ness. The smaller the RMSE is, the better our pre-intervention predictions are. The bigger the RMSE is, the worse our pre-intervention predictions are. The reason this matters is because if we have good pre-intervention model predictions, we’re likely to have better post-intervention counterfactual predictions. After all, if our model tracks closely with the actually observed values in the pre period, then it likely a good representation of how the post-intervention counterfactual would look since our predictions come from untreated units only. If we have worse pre-intervention model predictions, the opposite is true because the model does not explain the pre-intervention period data well.</p>
<p>Let’s apply these ideas to our example. The RMSE here is about 7. Strictly speaking, this number isn’t so bad, and it’s certainly an improvement over the pure average of all controls (without an intercept). But look at what this means practically and focus on the pre-intervention period. The DID counterfactual <em>under</em>predicts the true values for California in the pre-intervention period from around 1970 to 1975. Beyond this, it also <em>over</em>estimates the observed California’s values between 1980 and 1988. This is particularly bad because if your predictions diverge significantly from the treated unit’s observed values in the years <em>right before</em> the intervention takes place, why would we think that the post-intervention smoking consumption predictions are valid?</p>
<p>This imbalance comes from a violation of the parallel trends assumption. Why might this be? Well, we included all 38 control units. All of our control units may not be comparable to California’s tobacco consumption trends. Take Kentucky or New Hampshire, for example, states that have very high smoking rates per capita. In the same way that outlier observations may corrupt an average, they equally may corrupt regression predictions for causal analysis.</p>
</section>
<section id="alternate-control-group" class="level3" data-number="7.4.6">
<h3 data-number="7.4.6" class="anchored" data-anchor-id="alternate-control-group"><span class="header-section-number">7.4.6</span> Alternate Control Group</h3>
<p>What if we used a different control group though? Suppose we altered the control group to be a smaller subset of controls. Say I use Montana, Colorado, Nevada, Connecticut. After all, why not? Montana, Colorado, and Nevada are all geographically quite close to California, and Connecticut has a similar preintervention trend of tobacco smoking to California.</p>
<div class="cell" data-engine="jupyter" data-execution_count="5">
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="treatmenteffects_files/figure-html/cell-6-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Well now! This certainly looks <strong>a lot</strong> more parallel than when we used all of our control units!! When we use the limited set of controls, <span class="math inline">\(\tau=-13.647\)</span>, with a confidence interval of <span class="math inline">\(\left[-14.549,-12.745\right]\)</span>. Think of how big of a reduction this is: when we used all control units (some of which are clearly different from California’s pre-1989 tobacco smoking trends), we come up with a decrease of 27 packs per capita, but when we use a more limited pool of controls, we get an ATT which implies a reduction of 13.6 packs per capita. That’s pretty much a reduction of <strong>100%</strong> in terms of the average treatment effect! We have cut our treatment effect <em>in half</em> by virtue of having a better control group.</p>
<p>In addition to the pre-intervention average trend of controls “looking” more parallel, we can confirm that the regression model with the alternate control group is superior to the original model in that the new control group reduces the bias from parallel trends imbalance. The RMSE for the alternate control group shrinks by <strong>140%</strong> compared to the original model. The fact that our RMSE shrinks by so much indicates the value of choosing the control group judisciously. By selecting a valid pool of controls, we not only decrease our model’s prediction errors, but we also gain more confidence in the true effect of our intervention, as opposed to the original estimate whose estimates were much wider.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>As with OLS, rarely will you do DD in the manner I’ve described it above. However, I feel that Stata and R, through their excellent computing capabilities, can largely obscure what’s going on when we use <code>reg</code> or <code>didregress</code>. Also, we can extend DD to instances where many units are treated at different time points. However, for the introductory level, I think DD with a single treated unit is more than adequate as a starting point.</p>
</div>
</div>
<p>Next, we’re going to do the exact same example in Stata, however, we’re going to take advantage of the features that Stata allows for to automate this process.</p>
</section>
<section id="streamlining-dd-in-econometrics-software" class="level3" data-number="7.4.7">
<h3 data-number="7.4.7" class="anchored" data-anchor-id="streamlining-dd-in-econometrics-software"><span class="header-section-number">7.4.7</span> Streamlining DD in Econometrics Software</h3>
<p>Say that we wished to estimate this in Stata. Here is what we’d do:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode stata code-with-copy"><code class="sourceCode stata"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="kw">clear</span> *</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>import delim <span class="st">"https://raw.githubusercontent.com/OscarEngelbrektson/SyntheticControlMethods/master/examples/datasets/smoking_data.csv"</span>, <span class="kw">clear</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>g treat = <span class="fu">cond</span>(state==<span class="st">"California"</span>,1,0)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>g <span class="kw">post</span> = <span class="fu">cond</span>(<span class="fu">year</span> &gt; 1988,1,0)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="kw">egen</span> id = <span class="fu">group</span>(state)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>xtset id <span class="fu">year</span>, <span class="fu">y</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>cls</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="kw">reg</span> cig i.treat##i.<span class="kw">post</span>, <span class="kw">vce</span>(cl id)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>I create a treatment variable called <code>treat</code> (<code>g</code> is short for the full command name, <code>generate</code>). I do this using the condititional function. You can type in <code>h cond</code> to see the help file, or the way to use the syntax. However for our purposes, just know that it creates a variable equal to 1 if the <code>state</code> variable is “California”, else 0 (because California is our treated unit). I then use the same to create a <code>post</code> variable, equal to 1 if the variable <code>year</code> is greater than 1988. I then generate a numeric variable that is a number that uniquely identifies each state in our dataset, using the <code>egen</code> command and its corresponding function <code>group</code>. I then use Stata’s <code>xtset</code> command to sort our data by <code>id</code> and <code>year</code>. As promised, we have 31 rows for all 39 units. I then clear the screen using <code>cls</code> so we can better focus on the regression estimates.</p>
<p>Now, we use <code>reg</code>, short for <code>regress</code>, to estimate the treatment effect. To do this, we use something called an interaction term. This will be covered more in other methods courses, but think about it like this: we can have a unit be treated, or not. We can have the year be before the treatment, or not. But, for our purposes, we’re interested in the effect of being both treated (California) AND being in the post-intervention period (after 1988). So, the regression model takes the form of <span class="math inline">\(y= (d_i \times \text{post}_t)\)</span>.</p>
<p>Below, we will see a table. The first coefficient we will see is <code>1.treat -14.359</code>. This is the exact same number as we fot estimating the baseline differences between the average of controls and the treated unit in the pre period. In other words, it is the effect of <code>treat</code> being 1 and <code>post</code> being 0. Similarly, <code>post</code> is the effect of <code>1.post</code> being equal to 1 and <code>treat</code> being 0. <code>treat#post 1 1 -27.34911</code> is the effect of both <code>treat</code> being 1 AND <code>post</code> being 1. It is our treatment effect coefficient. As usual, the constant <code>_cons</code> is the value we predict where all of our predictor variables are equal to 0. In this case, this is simply the empirical average of the control group in the pre period. We also can see the associated confidence intervals, t-statistics, and standard errors.</p>
<p>You may at this point be asking why I didn’t just show it like this in the first place: why bother with the original regression method at all, where we manually take the average of controls and and use it as a predictor in OLS? Why not just use this method and focus my discussion on that? The reason for this is because by doing it this way, Stata is obscuring important details from you.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./ols.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">OLS Explained</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
  </div>
</nav>
</div> <!-- /content -->



</body></html>