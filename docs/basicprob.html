<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Econometrics for Policy Analysis - 3&nbsp; Basic Probability Theory</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./stataintro.html" rel="next">
<link href="./module1.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Basic Probability Theory</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Econometrics for Policy Analysis</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Syllabus: PMAP 4041, Fall 2024</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./module1.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Data and Policy Studies</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Mathematics and Econometric Theory</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./basicprob.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Basic Probability Theory</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stataintro.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Introduction to Stata</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./asymptotic.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Asymptotic Theory</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./correlation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Correlation and Association</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ols.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">OLS Explained</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">Applied Research Methods</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./treatmenteffects.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Causal Inference</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./dd.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Difference-in-Differences</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./present.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Presenting Results</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#descriptive-statistics" id="toc-descriptive-statistics" class="nav-link active" data-scroll-target="#descriptive-statistics"><span class="toc-section-number">3.1</span>  Descriptive Statistics</a>
  <ul class="collapse">
  <li><a href="#means-arithmetic-and-median" id="toc-means-arithmetic-and-median" class="nav-link" data-scroll-target="#means-arithmetic-and-median"><span class="toc-section-number">3.1.1</span>  Means: Arithmetic and Median</a></li>
  <li><a href="#variance" id="toc-variance" class="nav-link" data-scroll-target="#variance"><span class="toc-section-number">3.1.2</span>  Variance</a></li>
  </ul></li>
  <li><a href="#hypothesis-testing" id="toc-hypothesis-testing" class="nav-link" data-scroll-target="#hypothesis-testing"><span class="toc-section-number">3.2</span>  Hypothesis Testing</a>
  <ul class="collapse">
  <li><a href="#one-group-t-test" id="toc-one-group-t-test" class="nav-link" data-scroll-target="#one-group-t-test"><span class="toc-section-number">3.2.1</span>  One Group T-Test</a></li>
  <li><a href="#two-group-t-test" id="toc-two-group-t-test" class="nav-link" data-scroll-target="#two-group-t-test"><span class="toc-section-number">3.2.2</span>  Two-Group T-Test</a></li>
  </ul></li>
  <li><a href="#uncertainty-around-the-mean" id="toc-uncertainty-around-the-mean" class="nav-link" data-scroll-target="#uncertainty-around-the-mean"><span class="toc-section-number">3.3</span>  Uncertainty Around the Mean</a>
  <ul class="collapse">
  <li><a href="#confidence-intervals-and-the-normal-distribution" id="toc-confidence-intervals-and-the-normal-distribution" class="nav-link" data-scroll-target="#confidence-intervals-and-the-normal-distribution"><span class="toc-section-number">3.3.1</span>  Confidence Intervals and the Normal Distribution</a></li>
  <li><a href="#constructing-a-confidence-interval" id="toc-constructing-a-confidence-interval" class="nav-link" data-scroll-target="#constructing-a-confidence-interval"><span class="toc-section-number">3.3.2</span>  Constructing a Confidence Interval</a></li>
  </ul></li>
  <li><a href="#a-brief-word-on-practical-significance" id="toc-a-brief-word-on-practical-significance" class="nav-link" data-scroll-target="#a-brief-word-on-practical-significance"><span class="toc-section-number">3.4</span>  A Brief Word on Practical Significance</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><span class="toc-section-number">3.5</span>  Summary</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Basic Probability Theory</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>Human beings are awestruck at uncertainty in everyday life. In the elder days, the Greeks consulted Oracles at Delphi, the Vikings Seers, the samurai onmyōji, and, more recently, horoscopes/birth charts to make sense of happenings. Of these, however, only one has taken the throne of mathematical statistics: probability. Probability is a formalized system which allows us, under differing philosophies (Frequentism and Bayesianism), to rigorously make sense of events that occur.</p>
<p>More concretely, probability is a measure of the likelihood that an event will occur. It ranges from 0 to 1, where 0 indicates impossibility and 1 indicates certainty. Generally, there are two kinds of probabilities econometricians and policy analysts are concerned with: discrete random variables and continuous random variables. Why <em>random</em>? Well, because the event <em>may occur or not</em>. If a coin had only heads, only tails, or a die only had the number 1 on it, there’s no uncertainty anymore and probability wouldn’t be needed. But in real life, outcomes are essentially never guranteed. <em>Discrete</em> random variables have finite values they can take on. (heads or tails for the coin). By extension, a continuous random variable can take on infinitely many values. Suppose we have data on the width of a coke can or the amount of time in minutes spent studying. These are uncountable in the sense that they can have so many different values that they can’t be easily counted.</p>
<p>To fix ideas, let’s begin with the idea of a sample space, which we denote by the uppercase Greek letter “Omega”, <span class="math inline">\(\Omega\)</span>. This represents the set of all possible outcomes for some <em>instance</em> or experiment. For example, suppose we have a die of 3 sides numbered 1, 2, and 3, which we cast to see what number faces up. In our case, <span class="math inline">\(\Omega=\{1,2,3\}\)</span>. Any collection of these outcomes we call events. How then do we assign probability to this event? Say we ask for the probability of getting an odd number for a singular die cast, or <span class="math inline">\(A=\{1,3\}\)</span>. What are the odd numbers in <span class="math inline">\(1,2,3\)</span>? 1 and 3. Since there are two of these, over three possible outcomes, the probability is just two-thirds. Formally, the way we’d write this is <span class="math display">\[
\mathbb{E}\left[\mathbf{1}\left\{ A\right\} \right]=1\times P(A)+0\times P(A^{\prime})=\left(2\right)\frac{1}{3}+0=\frac{2}{3}
\]</span> Here, <span class="math inline">\(A\)</span> is our event of interest (getting a 1 or 3), and <span class="math inline">\(A^{\prime}\)</span> (<em>not A</em>) is the probability of A not occuring.</p>
<section id="descriptive-statistics" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="descriptive-statistics"><span class="header-section-number">3.1</span> Descriptive Statistics</h2>
<p>Probability is rarely used in a vacuum, though. We typically, in the policy sciences, wish to take a given outcome from a set of outcomes and draw conclusions from it. To do this, we use descriptive statistics (also called <em>moments</em>) to summarize probabilities. These moments map on to variables aside from coin flips- however to truly understand this, we’d need to introduce integration and <a href="https://zhentaoshi.github.io/Econ5121A/probability.html#introduction">other topics in math</a> which we can’t cover here.</p>
<section id="means-arithmetic-and-median" class="level3" data-number="3.1.1">
<h3 data-number="3.1.1" class="anchored" data-anchor-id="means-arithmetic-and-median"><span class="header-section-number">3.1.1</span> Means: Arithmetic and Median</h3>
<p><a href="https://www.youtube.com/watch?v=uhxtUt_-GyM&amp;list=PL1328115D3D8A2566&amp;index=1">The first moment</a> is called the <strong>average/arithmetic mean</strong>. The formula for the mean, also called the <em>expected value</em> (denoted by <span class="math inline">\(\mathbb E\)</span>) is <span class="math display">\[
\bar{x} = \mathbb{E}[X]=\frac{1}{N}\sum_{i=1}^{N}x_i
\]</span> where <span class="math inline">\(\bar{x}\)</span> is the mean, <span class="math inline">\(N\)</span> is the number of values, and <span class="math inline">\(x_i\)</span> represents the <span class="math inline">\(i\text{-th}\)</span> value in the sequence. The uppercase Greek letter “sigma” means summation, or <span class="math inline">\(\sum_{i=1}^{N} x_i\)</span>. It adds the values from <span class="math inline">\(i = 1\)</span> to <span class="math inline">\(N.\)</span> For a discrete random variable, the expected value is</p>
<p><span class="math display">\[
\mathbb{E}[X] = \sum_{i=1}^{N} x_i \cdot P(x_i).
\]</span> So for our die, the expected value is <span class="math display">\[
\mathbb{E}[X] = 1 \cdot \frac{1}{3} + 2 \cdot \frac{1}{3} + 3 \cdot \frac{1}{3} = \frac{1 + 2 + 3}{3} = 2
\]</span> For a coin, the expected value (assuming it is fair) is 0.5. Suppose we have a room of 10 men and 40 women, where women take the value of 1 and men the value of 0. The average number of women in the room is <span class="math inline">\(\frac{40}{50}\)</span>. This means the expected value of women in the room is .8. In other words, if we randomly selected a person from the room 10 times, we’d expect about 8 of them to be women. We can take averages with things aside from die and coins too. Naturally, if the amount of water in one giant jug was 5 liters and in another jug there is 7 liters, the average liters of water in the sample is <span class="math inline">\(\frac{1}{N}\sum_{i=1}^{N} x_i = \frac{1}{2}\sum_{i=1}^{2} 5+7=6\)</span> liters. Now we should distinguish between the population and sample statistics: the sample is that subset of the population that we can get. We can rarely sample every single American in the country (the population), but a random (or representative) sample of 3000 Americans, say, is just fine. This difference is important: outside of simulations, we never can get every single datapoint for all our interventions of interest. So, we collect a sample which approximiates that population we are truly interested in.</p>
<p>The median, or the middle number, is also a type of average. It is less influenced by outliers than the average is. Suppose we have a dataset of years of education across a group of people in a neighborhood, <span class="math inline">\(A=\{5,6,7,9,18\}\)</span>. The middle number here is 7 (since two numbers lie to the let and right of 7). But let’s consider the issue deeper: suppose we were to use the average years of education at the average. For us, we have <span class="math display">\[
\frac{1}{5} \times \sum_{i=1}^{5} 5 + 6 + 7 + 9 + 18 =\frac{45}{5}=9
\]</span> The mean and median produce differing values. If we were to use the mean, we’d conclude the average person in this sample is in high school. When in fact, as a raw number, the modal respondent is a middle schooler with one elementary schooler. Thus, we can see that the average is influenced by outliers (in this case, somebody in graduate school). The classic joke is that when Bill Gates walks into a bar, everyone, <em>on average</em>, is a billionaire.</p>
</section>
<section id="variance" class="level3" data-number="3.1.2">
<h3 data-number="3.1.2" class="anchored" data-anchor-id="variance"><span class="header-section-number">3.1.2</span> Variance</h3>
<p>The <strong>variance</strong> is <a href="https://www.youtube.com/watch?v=Qf3RMGXR-h8&amp;list=PL1328115D3D8A2566&amp;index=4">the second moment</a>. It represents the average squared differences from a point. For a random variable <span class="math inline">\(X\)</span>, the sample variance is denoted as <span class="math inline">\(s^2 = \frac{1}{N-1} \sum_{i=1}^{N} (x_i - \bar{x})^2\)</span>. For an intuitive example, suppose we have two middle schoolers in a room, one who reads at 6th grade level and the other at 8th grade level, <span class="math inline">\(A=\{6,8\}\)</span>. The sum of squared differences of each of these datapoints from the mean is (7) is 2, since 6 is 1 less than 7, and 8 is 1 more than 7. So, our sample variance is 2. The variance simply reflects the average distance of each data point from the center/mean of our observations. In practice however, we must correct for uncertainty about our sample estimate. So we subtract by 1 in the denominator. This is called <a href="https://math.oxford.emory.edu/site/math117/besselCorrection/">Bessel’s correction</a>. Subtracting 1 factors in uncertainty, since practically we are unsure about the “true” average in a population. When we do this, we get <span class="math inline">\(\frac{2}{2-1}\)</span>, making the new bias corrected variance be equal to 2.</p>
<p>The square root of our sample variance is what’s called the <a href="https://youtu.be/HvDqbzu0i0E?list=PL1328115D3D8A2566&amp;t=328">standard deviation</a> from the mean. Why standard? The raw variance is <em>not</em> in the same units as our original data. When we take the square root, we may interpret this as the “standardized” distance from the mean. For this simple example of the students, we can round the standard deviation down to 1, since <span class="math inline">\(\sqrt{2}=1.41\)</span>. When we think about it, it makes sense. If you’re at a middle school where the average reading level is 7th grade, people who read at 6th grade level are simply 1 year below the average, and those at 8th grade 1 year more than the average.</p>
<p>Some might wonder why we’re squaring these differences from the mean. The squared differences gives more weight to outliers, or datapoints that are very far from the mean. Suppose <span class="math inline">\(A=\{6, 8, 18\}\)</span>. The average of this is 10.6. Person 1 and 2 are only 4.6 and 2.6 years less than the mean. But someone in middle school with a graduate in college reading level at 18 years is very, very, very far from the mean (practically speaking). The squared differences themselves are 21.79, 7.13, and 53.77, and the sample standard deviation is roughly 6.43. Had we not squared the differences, we’d get a standard deviation of 4.89. So, we square the larger differences to assign more weight to large outliers, since not doing so would basically treat the middle schooler with a college graduate reading level as roughly equal to those who are much closer to the average of 10. The variance is also understood in <a href="https://stats.libretexts.org/Bookshelves/Introductory_Statistics/Inferential_Statistics_and_Probability_-_A_Holistic_Approach_(Geraghty)/03%3A_Descriptive_Statistics/3.02%3A_Measures_of_Variability">other contexts</a> like weather.</p>
</section>
</section>
<section id="hypothesis-testing" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="hypothesis-testing"><span class="header-section-number">3.2</span> Hypothesis Testing</h2>
<p>In public policy we oftentimes wish to test hypotheses. A hypothesis is a statement about the world that we wish to determine the validity of. For example, we could hypothesize that the average math score for a scool is 86, or we can hypothesize that black people use welfare less than white people. We are always testing our hypothesis (which we call the research hypothesis, <span class="math inline">\(H_R\)</span>) against a scenario where this hypothesis is wrong (the null hypothesis, <span class="math inline">\(H_{0}\)</span>). That is, we start off by assuming the math score is not different from 86 or that blacks and whites use welfare at the same rates. We only change our minds in light of compelling evidence. If this confuses you, imagine we had a courtroom where the burden of proof is now shifted on the defense to prove their client innocent. We would never be okay with presuming guilt. No, we’d presume the null hypothesis is true (the person is innocent until proven guilty), saying that the people making the positive claim of guilt are the ones who must supply enough evidence to convince us otherwise. In research, there are many ways to test a hypothesis, but the first way we will go over for this is by employing a t-test. The t-test produces a t-statistic, or a measure of how extreme our estimated sample mean is relative to a hypothesized mean or comparison group mean. The t-statistic is a measure of how many standard errors away from the population/hypothesized mean our observed mean is.</p>
<section id="one-group-t-test" class="level3" data-number="3.2.1">
<h3 data-number="3.2.1" class="anchored" data-anchor-id="one-group-t-test"><span class="header-section-number">3.2.1</span> One Group T-Test</h3>
<p>First we cover the one-sample t-test, where we compare our research hypothesis against some known/predefined statistic. If I ask you what you think the average literacy rate is in the population of Americans, you may give different answers like “I think it’s at the 9th grade level”, “I think the average literacy level is less than the 6th grade level” or “I think the average literacy rate is different from 0”. Each of these forms sets of testable hypotheses. In the first case, <span class="math inline">\(H_R\)</span> is “The literacy rate is equal to 9th grade.” In the second case, <span class="math inline">\(H_R\)</span> is “The literacy rate is less than the 6th grade level.” Finally, we’d say <span class="math inline">\(H_R\)</span> for case 3 is “I think the literacy rate in America is not 0” (or, some significant portion of the population can read). Formally, we denote these hypotheses as</p>
<p><span class="math display">\[
\begin{aligned}
&amp; H_{R}: L=9 \\
&amp;H_{R}: L &lt; 6 \\
&amp;H_{R}: L \neq 0.
\end{aligned}
\]</span></p>
<p>Our corresponding null hypotheses (the one we first assume) is</p>
<p><span class="math display">\[
\begin{aligned}
&amp; H_{0}: L \neq 9 \\
&amp;H_{0}: L \geq 6 \\
&amp;H_{0}: L = 0.
\end{aligned}
\]</span></p>
<p>we simply take a of sample the population somehow (which is usually taken care of for us in census data/compiled statistics). We then calculate the sample average of the grade level of our sample (ranging from 0 being illiterate and 16+ which means postgraduate). Let’s visualize this.</p>
<div class="cell" data-engine="jupyter" data-execution_count="1">
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="basicprob_files/figure-html/cell-2-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>This is a histogram. It shows a distribution of data. To better conceptualize it, imagine the height of the histogram (the y axis) represents the number of people in the data who take on the values on the x-axis. So, roughly 70 people have a literacy level of 8. In this case I generated a sample of 500 people with a small amount of variance. The average literacy rate in this population is 8 (for 8th grade). We now wish to see if our population mean (of 8th grade) is different from the researcher mean (9, 6, and 0). The formula for the one-sample t-statistic is</p>
<p><span class="math display">\[
t = \frac{\bar{x} - \mu_R}{\frac{s}{\sqrt{n}}}.
\]</span> Let’s parse these terms. In the numerator we take the difference of our sample mean (<span class="math inline">\(\bar x\)</span>, the mean we in fact observe in our dataset) versus our hypothetical mean that we are testing our sample mean against, denoted as <span class="math inline">\(\mu_R\)</span> (“myoo-sub R”). The denominator is the standard error, which is the standard deviation divided by the square root of our sample size. For example, here’s how we’d do this with the null hypothesis for 0 (that is, our sample mean is different from 0).</p>
<p><span class="math display">\[
t = \frac{\bar{x} - \mu_R}{\frac{s}{\sqrt{n}}}=\frac{7.949 - 0}{\frac{1.9983}{\sqrt{500}}}=88.95.
\]</span> In other words, the sample mean is 88.95 standard errors away from the hypothesized mean (0 in this case). We can do the analogous thing for reading level 6 and 9, where we substitute 0 in the above formula for those respective numbers. We can do this in Stata like</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode stata code-with-copy"><code class="sourceCode stata"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="kw">ttesti</span> 500 7.949 1.9983 0 <span class="co">// sample size, average, standard deviation, hypothesized mean</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>One-<span class="kw">sample</span> t <span class="kw">test</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>------------------------------------------------------------------------------</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>         |     Obs        Mean    Std. err.   Std. <span class="kw">dev</span>.   [95% conf. interval]</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>---------+--------------------------------------------------------------------</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>       x |     500       7.949    .0893667      1.9983    7.773419    8.124581</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>------------------------------------------------------------------------------</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">mean</span> = <span class="kw">mean</span>(x)                                                t =  88.9481</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>H0: <span class="kw">mean</span> = 0                                     Degrees <span class="kw">of</span> freedom =      499</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    Ha: <span class="kw">mean</span> &lt; 0                 Ha: <span class="kw">mean</span> != 0                 Ha: <span class="kw">mean</span> &gt; 0</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a> Pr(T &lt; t) = 1.0000         Pr(|T| &gt; |t|) = 0.0000          Pr(T &gt; t) = 0.0000</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="two-group-t-test" class="level3" data-number="3.2.2">
<h3 data-number="3.2.2" class="anchored" data-anchor-id="two-group-t-test"><span class="header-section-number">3.2.2</span> Two-Group T-Test</h3>
<p>We can also do a 2-group t-test, where we wish to compare average group differences. We can compare men and women, one city to another city, one city to many cities, and so on. For our purposes though, we’ll just compare one city to another one. I generate a sample of 10000 minutes (the unit of time) where one city has a mean production rate per minute of 6 and another of 14 with respective variances of 1.5 and 3. Say these means represent the average kilowatt usage for electricity, and the variances are how much production is spread out by the minute for each city (where city 2 clearly has a higher variance).</p>
<div class="cell" data-engine="jupyter" data-execution_count="2">
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="basicprob_files/figure-html/cell-3-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Here is how we’d calculate the t-statistic in this case.</p>
<p><span class="math display">\[
t = \frac{\bar{x}_1 - \bar{x}_2}{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}}
\]</span></p>
<p>Let’s parse these terms. Here <span class="math inline">\(\bar{x}_i\)</span> is the averge production rate of a city and <span class="math inline">\(s\)</span> denotes the variance for each city. The numerator represents the raw differences in means, and the denominator represents the pooled standard errors for both cities (recall how we calculated standard error above). Note however here we use the <em>variance</em>, not the standard deviation to compute t. Why? Well, each group may have different levels of spread in its measurements. We need to account for the variability in each sample to see if the means are truly different when we account for this spread in each sample because higher variance increases error. And, in a situation where there’s substantial variability in the data, it makes it much harder to say if the means differ in an appreciable manner. To compute the t-statistic, we plug in the values. For the denominator:</p>
<p><span class="math display">\[
\sqrt{\frac{1.5}{10000} + \frac{3}{10000}} = \sqrt{\frac{1.5 + 3}{10000}} = \sqrt{\frac{4.5}{10000}} = \sqrt{0.00045}
\]</span> which yields <span class="math display">\[
\sqrt{0.00045} \approx 0.0212.
\]</span></p>
<p>Now, calculate the t-statistic:</p>
<p><span class="math display">\[
t = \frac{6 - 14}{0.0212} = \frac{-8}{0.0212} \approx -377.36
\]</span></p>
<p>This means that the sample mean difference is 377 standard errors lower than what we’d expect (in this case assuming no difference). We can also infer that City B produces a lot more electricity than City 1.</p>
<p>By the way, we can also do this for other things too. Take the Proposition 99 example. We could take the mean differences in tobacco consumption after 1988, comparing California to other states that did not do the intervention. Here is some sample Stata code (you can use this for your paper, by the way)</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode stata code-with-copy"><code class="sourceCode stata"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="kw">clear</span> *</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>cls</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>u <span class="st">"https://github.com/jgreathouse9/FDIDTutorial/raw/main/smoking.dta"</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="kw">ttest</span> cigsale <span class="kw">if</span> <span class="fu">year</span> &gt; 1988, <span class="kw">by</span>(treat) <span class="fu">reverse</span> unequal</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>Two-<span class="kw">sample</span> t <span class="kw">test</span> with unequal variances</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>------------------------------------------------------------------------------</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>   Group |     Obs        Mean    Std. err.   Std. <span class="kw">dev</span>.   [95% conf. interval]</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>---------+--------------------------------------------------------------------</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>       1 |      12       60.35    3.487999    12.08278    52.67297    68.02703</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>       0 |     456    102.0581     1.10465    23.58887    99.88726     104.229</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>---------+--------------------------------------------------------------------</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>Combined |     468    100.9887    1.121973    24.27199    98.78393    103.1934</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>---------+--------------------------------------------------------------------</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>    <span class="fu">diff</span> |           -41.70811    3.658742               -49.59344   -33.82279</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>------------------------------------------------------------------------------</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>    <span class="fu">diff</span> = <span class="kw">mean</span>(1) - <span class="kw">mean</span>(0)                                      t = -11.3996</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>H0: <span class="fu">diff</span> = 0                     Satterthwaite's degrees <span class="kw">of</span> freedom =   13.314</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>    Ha: <span class="fu">diff</span> &lt; 0                 Ha: <span class="fu">diff</span> != 0                 Ha: <span class="fu">diff</span> &gt; 0</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a> Pr(T &lt; t) = 0.0000         Pr(|T| &gt; |t|) = 0.0000          Pr(T &gt; t) = 1.0000</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>From this, we’d suggest that the average effect of the intervention was a decrease of 41 packs per capita compared to other states that didn’t do the policy. The t-statistic in this case means that our estimate of the mean difference is 11 standard errors below that of the that of the average of states who did not do the policy.</p>
</section>
</section>
<section id="uncertainty-around-the-mean" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="uncertainty-around-the-mean"><span class="header-section-number">3.3</span> Uncertainty Around the Mean</h2>
<p>Typically we are concerend with the uncertainty of our estimates. Uncertainty around the mean is typically expressed through <strong>confidence intervals</strong>. A <a href="https://www.youtube.com/watch?v=6G3jMjAqNqM&amp;list=PLSQl0a2vh4HBNxqWanMyJobind_frsqzC">confidence interval</a> provides a range of values that, under certain conditions, contains the true population mean.</p>
<section id="confidence-intervals-and-the-normal-distribution" class="level3" data-number="3.3.1">
<h3 data-number="3.3.1" class="anchored" data-anchor-id="confidence-intervals-and-the-normal-distribution"><span class="header-section-number">3.3.1</span> Confidence Intervals and the Normal Distribution</h3>
<p>To understand confidence intervals, it’s essential to first grasp the role of <a href="https://www.youtube.com/watch?v=rzFX5NWojp0">a normal/Gaussian distribution</a>. The normal distribution is a continuous probability distribution characterized by its bell-shaped curve. We call it a continuous distribution because unlike coin flips, other data points can take on many values such as homicide rates, COVID-19 rates, and other metrics that can’t be broken into simple, countable groups. Most real-world phenomena, when measured, tend to follow a normal distribution (we will return to this in the lecture on asymptotic theory). A normal distribution is defined by its mean (<span class="math inline">\(\mu\)</span>) and standard deviation (<span class="math inline">\(\sigma\)</span>). The great thing about a normal distribuition is that we can prove that 68 and 95% of the data lie within 1 and 2 standard deviations of the mean. We will exploit this fact to construct a confidence interval for a statistic of interest.</p>
</section>
<section id="constructing-a-confidence-interval" class="level3" data-number="3.3.2">
<h3 data-number="3.3.2" class="anchored" data-anchor-id="constructing-a-confidence-interval"><span class="header-section-number">3.3.2</span> Constructing a Confidence Interval</h3>
<p>The most common confidence interval is the 95% confidence interval. This means that if we were to take many samples and repeat our analysis many times, the confidence interval contains the true average. Typically, we have only one sample to work with (and we rely on large-sample asymptotics to argue for the validity of our confidence intervals), but methods such as <a href="https://www.youtube.com/watch?v=TqOeMYtOc1w">bootstrapping</a> (where we simulate many such samples) may be employed to do this too. For our current purposes though, we construct a confidence interval for the population mean <span class="math inline">\(\mu\)</span>, we use the sample mean <span class="math inline">\(\bar{x}\)</span> and the standard error of the sample mean as we’ve defined them above.</p>
<p>For a 95% confidence interval, we use the critical value from the standard normal distribution, typically denoted as <span class="math inline">\(t^*\)</span>. For a 95% confidence level, <span class="math inline">\(t^* \approx 1.96\)</span> (<a href="https://www.youtube.com/watch?v=2fzYE-Emar0">since</a> approximately 95% of the data lie within 1.96 standard deviations from the mean in <a href="https://www.youtube.com/watch?v=2tuBREK_mgE">a standard normal distribution</a>). As ones sample size increases, the t-distribution converges to a standard normal distribution. This means 1.96 is a good approximation of a 95% confidence interval for all sample sizes greater than 30; otherwise, a different t-statistic would be used. In the old days, t-tables were used to do this, but now software handles much of this for us. By the way, we can construct other confidence intervals too. We can construct a 90, 99, or even 80% confidence intervals; however in science, we typically use the 95% CI. We usually interpret confidence intervals that contain 0 (say, [-1,1]) as being statistically insignificant. If the CI does not conatain 0 (say, [3,5]), we say it is significantly different from 0 (or, that the means are much different from one another).</p>
<section id="one-group-t-test-ci" class="level4" data-number="3.3.2.1">
<h4 data-number="3.3.2.1" class="anchored" data-anchor-id="one-group-t-test-ci"><span class="header-section-number">3.3.2.1</span> One Group T-Test CI</h4>
<p>I generated a 10,000 person sample of incomes (in 1000s). The true average is 50. We think the average is 60. The variance is 2. To estimate the confidence interval, we compute <span class="math display">\[
0.0277= 1.96 \times \frac{\sqrt{2}}{\sqrt{10000}}
\]</span> to get our standard error of the mean. Here, we see that we multiply our critical value of 1.96 by the standard error. This entire expression is our margin of error. Now, in order to characterize the range that the mean falls within, we simply do <span class="math display">\[
\text{CI} = \mu \pm \text{Margin of Error}=50 \pm 0.0277=(49.986,50.014).
\]</span></p>
<p>We interpret this as “Our sample mean is 50 thousand dollars. We are 95% confident that given the data, the real mean lies between 49.986 and 50.014 thousand dollars.” Since both these numbers are less than 60, our research hypothesis (<span class="math inline">\(H_R=60\)</span>) is likely incorrect, as 60 does not fall within these estimates. Therefore, we fail… to reject, the null hypothesis (the hypothesis of no difference).</p>
</section>
<section id="two-group-t-test-ci" class="level4" data-number="3.3.2.2">
<h4 data-number="3.3.2.2" class="anchored" data-anchor-id="two-group-t-test-ci"><span class="header-section-number">3.3.2.2</span> Two-Group T-Test CI</h4>
<p>Now, we can revisit the city example from the above and see if the means significantly differ, using the two-group t-test. We typically use this kind of t-test in situations where we wish to compare one group to another. The formula for the CI for the difference between two means is given by: <span class="math display">\[
CI = (\bar{x}_1 - \bar{x}_2) \pm t \times \sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}
\]</span></p>
<p>We know the values from the above, so we plug them in. We also use the critical value of 1.96, since this is the value we use for a 95% CI. First we compute the standard error using the variances and sample sizes for both groups: <span class="math display">\[
SE = \sqrt{\frac{1.5}{10000} + \frac{3}{10000}} = \sqrt{\frac{4.5}{10000}} = \sqrt{0.00045} \approx 0.0212.
\]</span> We now have a margin of error (using the critical value 1.96 as above) of:</p>
<p><span class="math display">\[
\text{Margin of Error} = t  \times SE = 1.96 \times 0.0212 \approx 0.0413
\]</span> We already know the mean difference is -8, so now we just plug that in and solve:</p>
<p><span class="math display">\[
CI = (-8) \pm 0.0413.
\]</span></p>
<p>So, the 95% confidence interval for the difference in means is: <span class="math display">\[
(-8 - 0.0413, -8 + 0.0413) = (-8.0413, -7.9587).
\]</span></p>
<p>This interval suggests that City 1 consumes significantly less, on average, than City 2. By the way, for those who are curious, if we just reversed the order of the numerator, we’d get the same result but it would be <span class="math inline">\((7.9587,8.0413)\)</span>, where we’d say that City 2 consumes significantly more than City 1. Using the Stata code block above, we’d say the true effect of the intervention lies between a reduction of 49.59344 to 33.82279 packs per capita, under quite heroic assumptions (but that’s for later).</p>
</section>
</section>
</section>
<section id="a-brief-word-on-practical-significance" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="a-brief-word-on-practical-significance"><span class="header-section-number">3.4</span> A Brief Word on Practical Significance</h2>
<p>To conclude, a word of caution: as we can see, the magnitude of the t-statistic and tightness of the CIs tend to scale with sample size. Consider the two group case: <span class="math display">\[
t = \frac{\bar{x}_1 - \bar{x}_2}{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}}.
\]</span></p>
<p>We can see that an increase in the sample size leads to a decrease in the overall denominator. Suppose for the denominator <span class="math inline">\(s^2=4\)</span> for both groups. If both groups have the size of 40, then we just have <span class="math inline">\(\sqrt{.1+.1}\)</span>. But if both groups have a sample size of 400, the then we have <span class="math inline">\(\sqrt{.01+.01}\)</span>. The reason this matters is because researchers oftentimes interpret the t-statistic and whether it’s greater than 1.96 as a measure of <em>practical</em> importance. But this is wrong! Since our t-statistic is <em>guaranteed</em> to increase with sample size, per the formulae above, at certain sample sizes it would be hard for our confidence intervals to contain 0 at all.</p>
<p>What this means as a matter of practicality is to always keep in mind your sample size and what would matter practically to people in real life. If you estimate that the price of one brand of bottled water, for example, costs 0.05 dollars more than another brand across all 50 states, and your t-statistic is 70 and your CI is [0.01,0.06], then do not claim (in isolation anyways) that this difference is very meaningful or earth-shattering, since they make either a penny more or 6 cents more. I say this because I do not want for you, in real life or in your papers, to apply these ideas mechanically. I want you to always keep in mind how statistics maps on to the real world. The t-statistic for a correlation coefficient or regression coefficient can be <em>statistically</em> significant but practically uninformative.</p>
</section>
<section id="summary" class="level2" data-number="3.5">
<h2 data-number="3.5" class="anchored" data-anchor-id="summary"><span class="header-section-number">3.5</span> Summary</h2>
<p>Probability theory is the stepping stone into using statistical methods for policy analysis. It is the foundation of decision-making in business, economics, and policy studies. It allows us to, in a principled way, approach the understanding of problems in a data driven, informative manner by taking simplified models and applying them to real world ideas. For many, the concepts covered here will be new material– indeed, the term “statistics” or “data analysis” can be intimidating to people at first glance. I believe the best way to introduce these topics is to keep a balanced perspective between technical mathematics and application. However, this course only scratches the very surface; the world of quantitative methods in policy analysis is a big one. For those of you interested in graduate school or who wish to use statistics for your future job, your mastery of this very essential material will not be in vain.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./module1.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Data and Policy Studies</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./stataintro.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Introduction to Stata</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>