<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Econometrics for Policy Analysis - 3&nbsp; Basic Probability Theory</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./asymptotic.html" rel="next">
<link href="./module1.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Basic Probability Theory</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Econometrics for Policy Analysis</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Syllabus: PMAP 4041, Fall 2024</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./module1.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Data and Policy Studies</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Mathematics and Econometric Theory</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./basicprob.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Basic Probability Theory</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./asymptotic.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Asymptotic Theory</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./correlation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Correlation and Association</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ols.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">OLS Explained</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./treatmenteffects.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Causal Inference</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">Applied Research Methods</span>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#descriptive-statistics" id="toc-descriptive-statistics" class="nav-link active" data-scroll-target="#descriptive-statistics"><span class="toc-section-number">3.1</span>  Descriptive Statistics</a>
  <ul class="collapse">
  <li><a href="#means-arithmetic-and-median" id="toc-means-arithmetic-and-median" class="nav-link" data-scroll-target="#means-arithmetic-and-median"><span class="toc-section-number">3.1.1</span>  Means: Arithmetic and Median</a></li>
  <li><a href="#variance" id="toc-variance" class="nav-link" data-scroll-target="#variance"><span class="toc-section-number">3.1.2</span>  Variance</a></li>
  </ul></li>
  <li><a href="#hypothesis-testing" id="toc-hypothesis-testing" class="nav-link" data-scroll-target="#hypothesis-testing"><span class="toc-section-number">3.2</span>  Hypothesis Testing</a>
  <ul class="collapse">
  <li><a href="#one-group-t-test" id="toc-one-group-t-test" class="nav-link" data-scroll-target="#one-group-t-test"><span class="toc-section-number">3.2.1</span>  One Group T-Test</a></li>
  <li><a href="#two-group-t-test" id="toc-two-group-t-test" class="nav-link" data-scroll-target="#two-group-t-test"><span class="toc-section-number">3.2.2</span>  Two-Group T-Test</a></li>
  </ul></li>
  <li><a href="#uncertainty-around-the-mean" id="toc-uncertainty-around-the-mean" class="nav-link" data-scroll-target="#uncertainty-around-the-mean"><span class="toc-section-number">3.3</span>  Uncertainty Around the Mean</a>
  <ul class="collapse">
  <li><a href="#confidence-intervals-and-the-normal-distribution" id="toc-confidence-intervals-and-the-normal-distribution" class="nav-link" data-scroll-target="#confidence-intervals-and-the-normal-distribution"><span class="toc-section-number">3.3.1</span>  Confidence Intervals and the Normal Distribution</a></li>
  <li><a href="#constructing-a-confidence-interval" id="toc-constructing-a-confidence-interval" class="nav-link" data-scroll-target="#constructing-a-confidence-interval"><span class="toc-section-number">3.3.2</span>  Constructing a Confidence Interval</a></li>
  </ul></li>
  <li><a href="#a-brief-word-on-practical-significance" id="toc-a-brief-word-on-practical-significance" class="nav-link" data-scroll-target="#a-brief-word-on-practical-significance"><span class="toc-section-number">3.4</span>  A Brief Word on Practical Significance</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><span class="toc-section-number">4</span>  Summary</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Basic Probability Theory</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>Human beings are awestruck at uncertainty in everyday life. In the elder days, the Greeks consulted Oracles at Delphi, the Vikings Seers, the samurai onmyōji, and, more recently, horoscopes/birth charts to make sense of happenings. Of these, however, only one has taken the throne of mathematical statistics: probability. Probability is a formalized system which allows us, under differing philosophies (Frequentism and Bayesianism), to rigorously make sense of events that occur.</p>
<p>More concretely, probability is a measure of the likelihood that an event will occur. It ranges from 0 to 1, where 0 indicates impossibility and 1 indicates certainty. Generally, there are two kinds of probabilities econometricians and policy analysts are concerned with: discrete random variables and continuous random variables. Why <em>random</em>? Well, because the event <em>may occur or not</em>. If a coin had only heads, only tails, or a die only had the number 1 on it, there’s no uncertainty anymore and probability wouldn’t be needed. But in real life, outcomes are essentially never guranteed. <em>Discrete</em> random variables have finite values they can take on. (heads or tails for the coin). By extension, a continuous random variable can take on infinitely many values. Suppose we have data on the width of a coke can or the amount of time in minutes spent studying. These are uncountable in the sense that they can have so many different values that they can’t be easily counted.</p>
<p>To fix ideas, let’s begin with the idea of a sample space, which we denote by the uppercase Greek letter “Omega”, <span class="math inline">\(\Omega\)</span>. This represents the set of all possible outcomes for some <em>instance</em> or experiment. For example, suppose we have a die of 3 sides numbered 1, 2, and 3, which we cast to see what number faces up. In our case, <span class="math inline">\(\Omega=\{1,2,3\}\)</span>. Any collection of these outcomes we call events. How then do we assign probability to this event? Say we ask for the probability of getting an odd number for a singular die cast, or <span class="math inline">\(A=\{1,3\}\)</span>. What are the odd numbers in <span class="math inline">\(1,2,3\)</span>? 1 and 3. Since there are two of these, over three possible outcomes, the probability is just two-thirds. Formally, the way we’d write this is <span class="math display">\[
\mathbb{E}\left[\mathbf{1}\left\{ A\right\} \right]=1\times P(A)+0\times P(A^{\prime})=\left(2\right)\frac{1}{3}+0=\frac{2}{3}
\]</span> Here, <span class="math inline">\(A\)</span> is our event of interest (getting a 1 or 3), and <span class="math inline">\(A^{\prime}\)</span> (<em>not A</em>) is the probability of A not occuring.</p>
<section id="descriptive-statistics" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="descriptive-statistics"><span class="header-section-number">3.1</span> Descriptive Statistics</h2>
<p>Probability is rarely used in a vacuum, though. We typically, in the policy sciences, wish to take a given outcome from a set of outcomes and draw conclusions from it. To do this, we use descriptive statistics (also called <em>moments</em>).</p>
<section id="means-arithmetic-and-median" class="level3" data-number="3.1.1">
<h3 data-number="3.1.1" class="anchored" data-anchor-id="means-arithmetic-and-median"><span class="header-section-number">3.1.1</span> Means: Arithmetic and Median</h3>
<p>The first moment is called the <strong>average/arithmetic mean</strong>. The formula for the mean, also called the <em>expected value</em> (denoted by <span class="math inline">\(\mathbb E\)</span>) is <span class="math display">\[
\bar{x} = \mathbb{E}[X]=\frac{1}{N}\sum_{i=1}^{N}x_i
\]</span> where <span class="math inline">\(\bar{x}\)</span> is the mean, <span class="math inline">\(N\)</span> is the number of values, and <span class="math inline">\(x_i\)</span> represents the <span class="math inline">\(i\text{-th}\)</span> value in the sequence. The uppercase Greek letter “sigma” means summation, or <span class="math inline">\(\sum_{i=1}^{N} x_i\)</span>. It adds the values from <span class="math inline">\(i = 1\)</span> to <span class="math inline">\(N.\)</span> For a discrete random variable, the expected value is</p>
<p><span class="math display">\[
\mathbb{E}[X] = \sum_{i=1}^{N} x_i \cdot P(x_i).
\]</span> So for our die, the expected value is <span class="math display">\[
\mathbb{E}[X] = 1 \cdot \frac{1}{3} + 2 \cdot \frac{1}{3} + 3 \cdot \frac{1}{3} = \frac{1 + 2 + 3}{3} = 2
\]</span> For a coin, the expected value (assuming it is fair) is 0.5. Suppose we have a room of 10 men and 40 women, where women take the value of 1 and men the value of 0. The average number of women in the room is <span class="math inline">\(\frac{40}{50}\)</span>. This means the expected value of women in the room is .8. In other words, if we randomly selected a person from the room 10 times, we’d expect about 8 of them to be women. We can take averages with things aside from die and coins too. Naturally, if the amount of water in one giant jug was 5 liters and in another jug there is 7 liters, the average liters of water in the sample is <span class="math inline">\(\frac{1}{N}\sum_{i=1}^{N} x_i = \frac{1}{2}\sum_{i=1}^{2} 5+7=6\)</span> liters.</p>
<p>The median, or the middle number, is also a type of average. It is less influenced by outliers than the average is. Suppose we have a dataset of years of education across a group of peopl in a neighborhood, <span class="math inline">\(A=\{5,6,7,9,18\}\)</span>. The middle number here is 7 (since two numbers lie to the let and right of 7). But let’s consider the issue deeper: suppose we were to use the average years of education at the average. For us, we have <span class="math display">\[
\frac{1}{5} \times \sum_{i=1}^{5} 5 + 6 + 7 + 9 + 18 =\frac{45}{5}=9
\]</span> The mean and median produce differing values. If we were to use the mean, we’d conclude the average person in this sample is in high school. When in fact, as a raw number, the modal respondent is a middle schooler with one elementary schooler. Thus, we can see that the average is influenced by outliers (in this case, somebody in graduate school). The classic joke is that when Bill Gates walks into a bar, everyone, <em>on average</em>, is a billionaire.</p>
</section>
<section id="variance" class="level3" data-number="3.1.2">
<h3 data-number="3.1.2" class="anchored" data-anchor-id="variance"><span class="header-section-number">3.1.2</span> Variance</h3>
<p>The <strong>variance</strong> is the second moment. For a random variable <span class="math inline">\(X\)</span>, the varaince is denoted <span class="math inline">\(\text{Var}(X)\)</span>, measures the spread of its values around the mean. For a discrete random variable, it is calculated as: <span class="math inline">\(\text{Var}(X) = \mathbb{E}[(X - \mathbb{E}[X])^2]\)</span>. Naturally, if all numbers in a set are the same [e.g., <span class="math inline">\(A=\{5,5\}\)</span>], there’s no variance (and the mean is just that number, as one would expect). For our die, the variance is: <span class="math display">\[
\text{Var}(X) = \frac{1}{3}[(1-2)^2 + (2-2)^2 + (3-2)^2] = \frac{1}{3}[1 + 0 + 1] = \frac{2}{3}.
\]</span></p>
<p>The sample variance is</p>
<p><span class="math display">\[
s^2 = \frac{1}{N-1} \sum_{i=1}^{N} (x_i - \bar{x})^2.
\]</span> The subtracting of 1 is called <a href="https://math.oxford.emory.edu/site/math117/besselCorrection/">Bessel’s correction</a> because it factors in uncertainty. Some might wonder why we’re squaring these differences. The main reason here is because it penalizes outliers, or datapoints that are far from the mean. For example, let’s say that we have three people’s years of education, <span class="math inline">\(A=\{1, 2, 15\}\)</span>. The average of this is 3. Person 1 and 2 are only 2 and 1 year less than the mean. But someone with 15 years of education varies a lot more from the mean, since a junior in college has 12 more years of school than a third grader. So, we square the large difference to penalize this disparity.</p>
<p>The square root of our variance is what’s called the standard deviation from the mean. It is a measure of how much the sample data deviate from the mean. This will become more apparent when we discuss probability distributions below.</p>
</section>
</section>
<section id="hypothesis-testing" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="hypothesis-testing"><span class="header-section-number">3.2</span> Hypothesis Testing</h2>
<p>In public policy we oftentimes wish to test hypotheses. A hypothesis is a statement about the world that we wish to determine the validity of. For example, we could hypothesize that the average math score for a scool is 86, or we can hypothesize that black people use welfare less than white people. We are always testing our hypothesis (which we call the research hypothesis, <span class="math inline">\(H_R\)</span>) against a scenario where this hypothesis is wrong (the null hypothesis, <span class="math inline">\(H_{0}\)</span>). That is, we start off by assuming the math score is not different from 86 or that blacks and whites use welfare at the same rates. We only change our minds in light of compelling evidence. If this confuses you, imagine we had a courtroom where the burden of proof is now shifted on the defense to prove their client innocent. We would never be okay with presuming guilt. No, we’d say that the people making the positive claim are the ones who must supply enough evidence to convince us otherwise. In research, one way doing this is by using something called a t-test.</p>
<section id="one-group-t-test" class="level3" data-number="3.2.1">
<h3 data-number="3.2.1" class="anchored" data-anchor-id="one-group-t-test"><span class="header-section-number">3.2.1</span> One Group T-Test</h3>
<p>First we cover the one-sample t-test, where we compare our research hypothesis against some known/predefined statistic. If I ask you what you think the average literacy rate is in the population of Americans, you may give different answers like “I think it’s at the 9th grade level”, “I think the average literacy level is less than the 6th grade level” or “I think the average literacy rate is different from 0”. Each of these forms sets of testable hypotheses. In the first case, <span class="math inline">\(H_R\)</span> is “The literacy rate is equal to 9th grade.” In the second case, <span class="math inline">\(H_R\)</span> is “The literacy rate is less than the 6th grade level.” Finally, we’d say <span class="math inline">\(H_R\)</span> for case 3 is “I think the literacy rate in America is not 0” (or, some significant portion of the population can read). Formally, we denote these hypotheses as</p>
<p><span class="math display">\[
\begin{aligned}
&amp; H_{R}: L=9 \\
&amp;H_{R}: L &lt; 6 \\
&amp;H_{R}: L \neq 0.
\end{aligned}
\]</span></p>
<p>Our corresponding null hypotheses (the ones we start by assuming) are</p>
<p><span class="math display">\[
\begin{aligned}
&amp; H_{0}: L \neq 9 \\
&amp;H_{0}: L &gt; 6 \\
&amp;H_{0}: L = 0.
\end{aligned}
\]</span></p>
<p>we simply take a of sample the population somehow (which is usually taken care of for us in census data/compiled statistics). We then calculate the sample average of the grade level of our sample (ranging from 0 being illiterate and 16+ which means postgraduate). Let’s visualize this.</p>
<div class="cell" data-engine="jupyter" data-execution_count="1">
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="basicprob_files/figure-html/cell-2-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>This is a histogram. It shows a distribution of data. To better conceptualize it, imagine the height of the histogram (the y axis) represents the number of people in the data who take on the values on the x-axis. So, roughly 70 people have a literacy level of 8.</p>
<p>In this case I generated a sample of 500 people with a small amount of variance. The average literacy rate in this population is 8 (for 8th grade). We now wish to see if our population mean (of 8th grade) is different from the researcher mean (9, 6, and 0). To do this, we need what’s called a t-statistic, which is a measure of deviation from the mean <em>when taking into account</em> the standard deviation from the mean and sample size. The formula for this simple t-statistic is</p>
<p><span class="math display">\[
t = \frac{\bar{x} - \mu_R}{\frac{s}{\sqrt{n}}}.
\]</span> Let’s parse these terms. In the numerator we take the difference of our sample mean (<span class="math inline">\(\bar x\)</span>, the mean we in fact observe in our dataset) versus our hypothetical mean that we are testing our sample mean against, denoted as <span class="math inline">\(\mu_R\)</span> (“myoo-sub R”). The denominator is the standard error, which is the standard deviation divided by the square root of our sample size. For example, here’s how we’d do this with the null hypothesis for 0 (that is, our sample mean is different from 0).</p>
<p><span class="math display">\[
t = \frac{\bar{x} - \mu_R}{\frac{s}{\sqrt{n}}}=\frac{7.949 - 0}{\frac{1.9983}{\sqrt{500}}}=88.95.
\]</span> In other words, our average literacy grade level is 88 times that of what we would expect given our standard error.</p>
</section>
<section id="two-group-t-test" class="level3" data-number="3.2.2">
<h3 data-number="3.2.2" class="anchored" data-anchor-id="two-group-t-test"><span class="header-section-number">3.2.2</span> Two-Group T-Test</h3>
<p>We can also do a 2-group t-tests, where we wish to compare average group differnces. We can compare men and women, one city to another city, one city to many cities, and so on. For our purposes though, we’ll just compare one city to another one. I generate a sample of 20000 where one city has a mean of 6 and another of 14 with respective standard deviations of 1.5 and 3.</p>
<div class="cell" data-engine="jupyter" data-execution_count="2">
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="basicprob_files/figure-html/cell-3-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Here is how we’d calculate the t-statistic in this case.</p>
<p><span class="math display">\[
t = \frac{\bar{x}_1 - \bar{x}_2}{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}}
\]</span></p>
<p>where <span class="math inline">\(\bar{x}\)</span> is the averge mean of a city and <span class="math inline">\(s\)</span> denotes the variance for each city. We plug in the values. For the denominator:</p>
<p><span class="math display">\[
\sqrt{\frac{1.5}{10000} + \frac{3}{10000}} = \sqrt{\frac{1.5 + 3}{10000}} = \sqrt{\frac{4.5}{10000}} = \sqrt{0.00045}
\]</span> which yields <span class="math display">\[
\sqrt{0.00045} \approx 0.0212.
\]</span></p>
<p>Now, calculate the t-statistic:</p>
<p><span class="math display">\[
t = \frac{6 - 14}{0.0212} = \frac{-8}{0.0212} \approx -377.36
\]</span></p>
</section>
</section>
<section id="uncertainty-around-the-mean" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="uncertainty-around-the-mean"><span class="header-section-number">3.3</span> Uncertainty Around the Mean</h2>
<p>Typically we are concerend with the uncertainty of our estimates. Uncertainty around the mean is typically expressed through <strong>confidence intervals</strong>. A confidence interval provides a range of values that, under certain conditions, contains the true population mean. Now we should distinguish between the population and sample statistics: the sample is that subset of the population that we can get. We can rarely sample every single American in the country (the population), but a random (or representative) sample of 3000 Americans, say, is just fine. This difference is important: outside of simulations, we never can get every single datapoint for all our interventions of interest. So, we collect a sample which approximiates that population.</p>
<section id="confidence-intervals-and-the-normal-distribution" class="level3" data-number="3.3.1">
<h3 data-number="3.3.1" class="anchored" data-anchor-id="confidence-intervals-and-the-normal-distribution"><span class="header-section-number">3.3.1</span> Confidence Intervals and the Normal Distribution</h3>
<p>To understand confidence intervals, it’s essential to first grasp the role of <a href="https://www.youtube.com/watch?v=rzFX5NWojp0">a normal/Gaussian distribution</a>. The normal distribution is a continuous probability distribution characterized by its bell-shaped curve. We call it a continuous distribution because unlike coin flips, other data points can take on many values such as homicide rates, COVID-19 rates, and other metrics that can’t be broken into simple, countable groups. Most real-world phenomena, when measured, tend to follow a normal distribution (we will return to this in the lecture on asymptoyic theory). A normal distribution is defined by its mean (<span class="math inline">\(\mu\)</span>) and standard deviation (<span class="math inline">\(\sigma\)</span>). The great thing about a normal distribuition is that we can prove that 68 and 95% of the data lie within 1 and 2 standard deviations of the mean. We will exploit this fact to construct a confidence interval.</p>
</section>
<section id="constructing-a-confidence-interval" class="level3" data-number="3.3.2">
<h3 data-number="3.3.2" class="anchored" data-anchor-id="constructing-a-confidence-interval"><span class="header-section-number">3.3.2</span> Constructing a Confidence Interval</h3>
<p>The most common confidence interval is the 95% confidence interval. This means that if we were to take many samples and construct confidence intervals for each of them, approximately 95% of these intervals would contain the true population mean. Typically, we have only one sample to work with (and we rely on asymptotics to argue for the validity of our confidence intervals), but methods such as bootstrapping (where we simulate many such samples) may be employed to do this too. For our current purposes though, we construct a confidence interval for the population mean <span class="math inline">\(\mu\)</span>, we use the sample mean <span class="math inline">\(\bar{x}\)</span> and the standard error of the mean as we’ve defined them above.</p>
<p>For a 95% confidence interval, we use the critical value from the standard normal distribution, typically denoted as <span class="math inline">\(t^*\)</span>. For a 95% confidence level, <span class="math inline">\(t^* \approx 1.96\)</span> (<a href="https://www.youtube.com/watch?v=2fzYE-Emar0">since</a> approximately 95% of the values lie within 1.96 standard deviations from the mean in a standard normal distribution). If the t-statistics from our t-tests (such as the ones from above) are greater, in absolute value, than 1.96, we typically interpret this as a major difference from the null hypothesis (that there’s no relationship/the means are not significantly different). Note, 95% CIs do not mean 95% of the sample data lies within this interval. Confidence intervals are statements about the mean. Instead, it means that if we were to take many samples and construct intervals in the same way for a mean of interest, 95% of those intervals would contain the true population mean. We usually interpret confidence intervals that contain 0 (say, [-1,1]) as being insignificant. By extension, if the CI does not conatain 0 (say, [3,5]), we say it is significantly different from 0 (or, that the means are much different from one another).</p>
<section id="one-group-t-test-ci" class="level4" data-number="3.3.2.1">
<h4 data-number="3.3.2.1" class="anchored" data-anchor-id="one-group-t-test-ci"><span class="header-section-number">3.3.2.1</span> One Group T-Test CI</h4>
<p>I generated a 10,000 person sample of incomes (in 1000s). The true average is 50. We think the average is 60. The standard deviation is the square root of 2. To estimate the confidence interval, we compute <span class="math display">\[
0.0277= 1.96 \times \frac{\sqrt{2}}{\sqrt{10000}}
\]</span> to get our standard error of the mean. Now, in order to characterize the range that the mean falls within, we simply do <span class="math display">\[
\text{CI} = \mu \pm \text{Margin of Error}=50 \pm 0.0277=(49.986,50.014).
\]</span></p>
<p>We interpret this as “Our sample mean is 50 thousand dollars. We are 95% confident that given the data, the real mean lies between 49.986 and 50.014 thousand dollars.” Since both these numers are less than 60, our research hypothesis (<span class="math inline">\(H_R=60\)</span>) is likely incorrect, as 60 does not fall within these estimates.</p>
</section>
<section id="two-group-t-test-ci" class="level4" data-number="3.3.2.2">
<h4 data-number="3.3.2.2" class="anchored" data-anchor-id="two-group-t-test-ci"><span class="header-section-number">3.3.2.2</span> Two-Group T-Test CI</h4>
<p>Now, we can revisit the city example using product weight from the above and see if the means significantly differ. We typically use this kind of t-test in situations where we wish to compare one group to another. The formula for the CI for the difference between two means is given by: <span class="math display">\[
CI = (\bar{x}_1 - \bar{x}_2) \pm t \times \sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}
\]</span></p>
<p>We know the values from the above, so we plug them in. We also use the critical value of 1.96, since this is the value we use for a 95% CI. First we compute the standard error using the variances and sample sizes for both groups: <span class="math display">\[
SE = \sqrt{\frac{1.5}{10000} + \frac{3}{10000}} = \sqrt{\frac{4.5}{10000}} = \sqrt{0.00045} \approx 0.0212.
\]</span> We now have a margin of error (using the critical value 1.96 as above) of:</p>
<p><span class="math display">\[
\text{Margin of Error} = t  \times SE = 1.96 \times 0.0212 \approx 0.0413
\]</span> We already know the mean difference is -8, so now we just plug that in and solve:</p>
<p><span class="math display">\[
CI = (-8) \pm 0.0413.
\]</span></p>
<p>So, the 95% confidence interval for the difference in means is: <span class="math display">\[
(-8 - 0.0413, -8 + 0.0413) = (-8.0413, -7.9587).
\]</span></p>
<p>This interval suggests that City 1 consumes significantly less, on average, than City 2. By the way, for those curious, if we just reversed the order of the numerator, we’d get the same result but it would be <span class="math inline">\((7.9587,8.0413)\)</span>, where we’d say that City 2 consumes significantly more than City 1.</p>
</section>
</section>
</section>
<section id="a-brief-word-on-practical-significance" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="a-brief-word-on-practical-significance"><span class="header-section-number">3.4</span> A Brief Word on Practical Significance</h2>
<p>To conclude, a word of caution: as we can see, the magnitude of the t-statistic and tightness of the CIs tend to scale with sample size. Consider the two group case: <span class="math display">\[
t = \frac{\bar{x}_1 - \bar{x}_2}{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}}.
\]</span></p>
<p>We can see that an increase in the sample size leads to a decrease in the overall denominator. Supoose for the denominator <span class="math inline">\(s^2=4\)</span> for both groups. If both groups have the size of 40, then we just have <span class="math inline">\(\sqrt{.1+.1}\)</span>. But if both groups have a sample size of 400, the then we have <span class="math inline">\(\sqrt{.01+.01}\)</span>. The reason this matters is because researchers oftentimes interpret the t-statistic and whether it’s greater than 1.96 as a measure of practical importance. But this is wrong! Since our t-statistic is guaranteed to increase with sample size, per the formulae above, at certain sample sizes it would be hard for our confience intervals to NOT contain 0/be significantly different.</p>
<p>What this means as a matter of practicality is to always keep in mind your sample size and what would matter practically to people in real life. If you estimate that the price of one brand of bottled water, for example, costs 0.05 dollars more than another brand across all 50 states, and your t-statistic is 70 and your CI is [0.01,0.06], then do not claim (in isolation anyways) that this difference is very meaningful or earth-shattering, since they make either a penny more or 6 cents more. In other words, the findings are statistically significant, but practically they are meaningless. The only way for this to really matter to anyone is by having some metric about how much each brand sold (in terms of individual water bottles) for us to reach any firm conclusion about how much this average difference matters. I say this because I do not want for you, in real life or in your papers, to apply these ideas mechanically. I want you to always keep in mind how statistics maps on to the real world.</p>
</section>
<section id="summary" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Summary</h1>
<p>Probability is the stepping stone into using statistical methods. It is the foundation of decisionmaking in business, economics, and policy analysis. For many, the concepts covered here will be new material– indeed, the term “statistics” or “data analysis” can be intimidating to people at first glance.</p>
<p>I believe the best way to introduce these topics is to keep a balanced perspective between mathematics and application. However, this course only scratches the very surface; the world of quantitative methods in policy analysis is a big one. For those of you interested in graduate school or who wish to use statistics for your future job, your mastery of this essential material will not be in vain.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./module1.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Data and Policy Studies</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./asymptotic.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Asymptotic Theory</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>